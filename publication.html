<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=us-ascii">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 15">
<meta name=Originator content="Microsoft Word 15">
<link rel=File-List href="publication.files/filelist.xml">
<link rel=Edit-Time-Data href="publication.files/editdata.mso">
<!--[if !mso]>
<style>
v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style>
<![endif]-->
<title>Eric Yang</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>yang</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor>Yi-Hsuan Yang</o:LastAuthor>
  <o:Revision>1245</o:Revision>
  <o:TotalTime>35369</o:TotalTime>
  <o:Created>2015-02-24T01:37:00Z</o:Created>
  <o:LastSaved>2025-04-11T05:57:00Z</o:LastSaved>
  <o:Pages>42</o:Pages>
  <o:Words>13202</o:Words>
  <o:Characters>75252</o:Characters>
  <o:Lines>627</o:Lines>
  <o:Paragraphs>176</o:Paragraphs>
  <o:CharactersWithSpaces>88278</o:CharactersWithSpaces>
  <o:Version>16.00</o:Version>
 </o:DocumentProperties>
 <o:OfficeDocumentSettings>
  <o:AllowPNG/>
 </o:OfficeDocumentSettings>
</xml><![endif]-->
<link rel=dataStoreItem href="publication.files/item0007.xml"
target="publication.files/props008.xml">
<link rel=themeData href="publication.files/themedata.thmx">
<link rel=colorSchemeMapping href="publication.files/colorschememapping.xml">
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:View>Print</w:View>
  <w:Zoom>140</w:Zoom>
  <w:TrackMoves>false</w:TrackMoves>
  <w:TrackFormatting/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-TW</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SplitPgBreakAndParaMark/>
   <w:UseFELayout/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="371">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="59" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Helvetica;
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Courier;
	panose-1:2 7 4 9 2 2 5 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-format:other;
	mso-font-pitch:fixed;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Tms Rmn";
	panose-1:2 2 6 3 4 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Helv;
	panose-1:2 11 6 4 2 2 2 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"New York";
	panose-1:2 4 5 3 6 5 6 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:System;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;
	mso-font-alt:"MS Mincho";
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:fixed;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:Batang;
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-alt:Batang;
	mso-font-charset:129;
	mso-generic-font-family:auto;
	mso-font-pitch:fixed;
	mso-font-signature:1 151388160 16 0 524288 0;}
@font-face
	{font-family:SimSun;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-alt:SimSun;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:1 135135232 16 0 262144 0;}
@font-face
	{font-family:PMingLiU;
	panose-1:2 2 5 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 684719354 22 0 1048577 0;}
@font-face
	{font-family:"MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;
	mso-font-alt:"MS Gothic";
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:Dotum;
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-alt:Dotum;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 151388160 16 0 524288 0;}
@font-face
	{font-family:SimHei;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-alt:SimHei;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 135135232 16 0 262144 0;}
@font-face
	{font-family:MingLiU;
	panose-1:2 2 5 9 0 0 0 0 0 0;
	mso-font-alt:MingLiU;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610611969 684719354 22 0 1048577 0;}
@font-face
	{font-family:Mincho;
	panose-1:2 2 6 9 4 3 5 8 3 5;
	mso-font-alt:Mincho;
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:fixed;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:Gulim;
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-alt:Gulim;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:fixed;
	mso-font-signature:1 151388160 16 0 524288 0;}
@font-face
	{font-family:Century;
	panose-1:2 4 6 4 5 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Angsana New";
	panose-1:2 2 6 3 5 4 5 2 3 4;
	mso-font-charset:222;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:16777217 0 0 0 65536 0;}
@font-face
	{font-family:"Cordia New";
	panose-1:2 11 3 4 2 2 2 2 2 4;
	mso-font-charset:222;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:16777217 0 0 0 65536 0;}
@font-face
	{font-family:Mangal;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:8192 0 0 0 0 0;}
@font-face
	{font-family:Latha;
	panose-1:2 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:262144 0 0 0 0 0;}
@font-face
	{font-family:Sylfaen;
	panose-1:1 10 5 2 5 3 6 3 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:12583555 0 0 0 13 0;}
@font-face
	{font-family:Vrinda;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Raavi;
	panose-1:2 0 5 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Shruti;
	panose-1:2 0 5 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Sendnya;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Gautami;
	panose-1:2 0 5 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Tunga;
	panose-1:0 0 4 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"Estrangelo Edessa";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:1;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536869121 1107305727 33554432 0 415 0;}
@font-face
	{font-family:"Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;
	mso-font-alt:"Yu Gothic";
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 134676480 16 0 131072 0;}
@font-face
	{font-family:DengXian;
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-alt:DengXian;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:1 135135232 16 0 262144 0;}
@font-face
	{font-family:"Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Calibri Light";
	panose-1:2 15 3 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1040178053 9 0 511 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1040178053 9 0 511 0;}
@font-face
	{font-family:DFKai-SB;
	panose-1:3 0 5 9 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:script;
	mso-font-pitch:fixed;
	mso-font-signature:3 135135232 22 0 1048577 0;}
@font-face
	{font-family:"Bodoni MT";
	panose-1:2 7 6 3 8 6 6 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:\83EF\5EB7\6977\66F8\9AD4W5;
	mso-font-charset:136;
	mso-generic-font-family:script;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536869121 1107305727 33554432 0 415 0;}
@font-face
	{font-family:DFKai-SB;
	mso-font-charset:136;
	mso-generic-font-family:script;
	mso-font-pitch:fixed;
	mso-font-signature:3 135135232 22 0 1048577 0;}
@font-face
	{font-family:PMingLiU;
	panose-1:2 1 6 1 0 1 1 1 1 1;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 684719354 22 0 1048577 0;}
@font-face
	{font-family:s\04E9;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"\@\83EF\5EB7\65B0\7BC6\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:DFKaiShu-SB-Estd-BF;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Microsoft YaHei";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:Verdana;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610610945 1073750107 16 0 415 0;}
@font-face
	{font-family:Marlett;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Arial Black";
	panose-1:2 11 10 4 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612049 1073772795 0 0 159 0;}
@font-face
	{font-family:"Bahnschrift Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiLight";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:Bahnschrift;
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiBold";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift Light SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiLight SemiConde";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiCondensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiBold SemiConden";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift Light Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiLight Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:"Bahnschrift SemiBold Condensed";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612025 2 0 0 415 0;}
@font-face
	{font-family:Candara;
	panose-1:2 14 5 2 3 3 3 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073783883 0 0 415 0;}
@font-face
	{font-family:"Candara Light";
	panose-1:2 14 5 2 3 3 3 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 2 0 0 415 0;}
@font-face
	{font-family:"Comic Sans MS";
	panose-1:3 15 7 2 3 3 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 19 0 0 159 0;}
@font-face
	{font-family:Consolas;
	panose-1:2 11 6 9 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-536869121 64767 1 0 415 0;}
@font-face
	{font-family:Constantia;
	panose-1:2 3 6 2 5 3 6 3 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:Corbel;
	panose-1:2 11 5 3 2 2 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073783883 0 0 415 0;}
@font-face
	{font-family:"Corbel Light";
	panose-1:2 11 3 3 2 2 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073783883 0 0 415 0;}
@font-face
	{font-family:Ebrima;
	panose-1:2 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610612641 33554497 2048 0 147 0;}
@font-face
	{font-family:"Franklin Gothic Medium";
	panose-1:2 11 6 3 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Gabriola;
	panose-1:4 4 6 5 5 16 2 2 13 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:-536870161 1342185547 0 0 159 0;}
@font-face
	{font-family:Gadugi;
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483645 33554432 12288 0 1 0;}
@font-face
	{font-family:Georgia;
	panose-1:2 4 5 2 5 4 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Impact;
	panose-1:2 11 8 6 3 9 2 5 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Ink Free";
	panose-1:3 8 4 2 0 5 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:536872591 1073741834 0 0 415 0;}
@font-face
	{font-family:"Javanese Text";
	panose-1:2 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-2147483645 8192 0 0 1 0;}
@font-face
	{font-family:"Leelawadee UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1560281085 0 65536 0 65793 0;}
@font-face
	{font-family:"Leelawadee UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1560281085 0 65536 0 65793 0;}
@font-face
	{font-family:"Lucida Console";
	panose-1:2 11 6 9 4 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482993 6144 0 0 31 0;}
@font-face
	{font-family:"Lucida Sans Unicode";
	panose-1:2 11 6 2 3 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147480833 14699 0 0 191 0;}
@font-face
	{font-family:"Malgun Gothic";
	panose-1:2 11 5 3 2 0 0 2 0 4;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1879048145 701988091 18 0 524289 0;}
@font-face
	{font-family:"\@Malgun Gothic";
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1879048145 701988091 18 0 524289 0;}
@font-face
	{font-family:"Malgun Gothic Semilight";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342174545 165641467 18 0 4063677 0;}
@font-face
	{font-family:"\@Malgun Gothic Semilight";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342174545 165641467 18 0 4063677 0;}
@font-face
	{font-family:"Microsoft Himalaya";
	panose-1:1 1 1 0 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-2147483645 65536 64 0 1 0;}
@font-face
	{font-family:"Microsoft JhengHei";
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-alt:"Microsoft JhengHei";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:679 684672000 22 0 1048585 0;}
@font-face
	{font-family:"Microsoft JhengHei UI";
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:679 684672000 22 0 1048585 0;}
@font-face
	{font-family:"\@Microsoft JhengHei UI";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:679 684672000 22 0 1048585 0;}
@font-face
	{font-family:"\5FAE\8EDF\6B63\9ED1\9AD4 Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147482969 684672000 22 0 1048585 0;}
@font-face
	{font-family:"\@\5FAE\8EDF\6B63\9ED1\9AD4 Light";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147482969 684672000 22 0 1048585 0;}
@font-face
	{font-family:"Microsoft JhengHei UI Light";
	panose-1:2 11 3 4 3 5 4 4 2 4;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147482969 684672000 22 0 1048585 0;}
@font-face
	{font-family:"\@Microsoft JhengHei UI Light";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147482969 684672000 22 0 1048585 0;}
@font-face
	{font-family:"Microsoft New Tai Lue";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 -2147483648 0 1 0;}
@font-face
	{font-family:"Microsoft PhagsPa";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 134217728 0 1 0;}
@font-face
	{font-family:"Microsoft Sans Serif";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-452972801 -1073717157 41 0 66047 0;}
@font-face
	{font-family:"Microsoft Tai Le";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 1073741824 0 1 0;}
@font-face
	{font-family:"Microsoft YaHei";
	panose-1:2 11 5 3 2 2 4 2 2 4;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718224464 22 0 262175 0;}
@font-face
	{font-family:"\@Microsoft YaHei";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718224464 22 0 262175 0;}
@font-face
	{font-family:"Microsoft YaHei UI";
	panose-1:2 11 5 3 2 2 4 2 2 4;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718224464 22 0 262175 0;}
@font-face
	{font-family:"\@Microsoft YaHei UI";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718224464 22 0 262175 0;}
@font-face
	{font-family:"Microsoft YaHei Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718209040 22 0 262175 0;}
@font-face
	{font-family:"\@Microsoft YaHei Light";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718209040 22 0 262175 0;}
@font-face
	{font-family:"Microsoft YaHei UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718209040 22 0 262175 0;}
@font-face
	{font-family:"\@Microsoft YaHei UI Light";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483001 718209040 22 0 262175 0;}
@font-face
	{font-family:"Microsoft Yi Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-2147483645 66562 524290 0 1 0;}
@font-face
	{font-family:MingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;
	mso-font-alt:MingLiU-ExtB;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 168296456 16 0 1048577 0;}
@font-face
	{font-family:PMingLiU-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU-ExtB;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 168296456 16 0 1048577 0;}
@font-face
	{font-family:MingLiU_HKSCS-ExtB;
	panose-1:2 2 5 0 0 0 0 0 0 0;
	mso-font-alt:MingLiU_HKSCS-ExtB;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 168296456 16 0 1048577 0;}
@font-face
	{font-family:"Mongolian Baiti";
	panose-1:3 0 5 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-2147483613 0 131072 0 1 0;}
@font-face
	{font-family:"\@MS Gothic";
	panose-1:2 11 6 9 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-536870145 1791491579 134217746 0 131231 0;}
@font-face
	{font-family:"MS UI Gothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 134217746 0 131231 0;}
@font-face
	{font-family:"\@MS UI Gothic";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 134217746 0 131231 0;}
@font-face
	{font-family:"MS PGothic";
	panose-1:2 11 6 0 7 2 5 8 2 4;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 134217746 0 131231 0;}
@font-face
	{font-family:"\@MS PGothic";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 134217746 0 131231 0;}
@font-face
	{font-family:"MV Boli";
	panose-1:2 0 5 0 3 2 0 9 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 0 256 0 1 0;}
@font-face
	{font-family:"Myanmar Text";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483645 0 1024 0 1 0;}
@font-face
	{font-family:"Nirmala UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130739165 33554506 512 0 1 0;}
@font-face
	{font-family:"Nirmala UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130739165 33554506 512 0 1 0;}
@font-face
	{font-family:"Palatino Linotype";
	panose-1:2 4 5 2 5 5 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870265 1073741843 0 0 415 0;}
@font-face
	{font-family:"Sans Serif Collection";
	panose-1:2 11 5 2 4 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2146983741 33579072 688914433 0 1 0;}
@font-face
	{font-family:"Segoe Fluent Icons";
	panose-1:5 10 1 2 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 268435456 0 0 1 0;}
@font-face
	{font-family:"Segoe MDL2 Assets";
	panose-1:5 10 1 2 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 268435456 0 0 1 0;}
@font-face
	{font-family:"Segoe Print";
	panose-1:2 0 6 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:655 0 0 0 159 0;}
@font-face
	{font-family:"Segoe Script";
	panose-1:3 11 5 4 2 0 0 0 0 3;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:655 0 0 0 159 0;}
@font-face
	{font-family:"Segoe UI";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1073683329 9 0 511 0;}
@font-face
	{font-family:"Segoe UI Black";
	panose-1:2 11 10 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1073800319 33 0 415 0;}
@font-face
	{font-family:"Segoe UI Emoji";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 33554432 134217728 0 1 0;}
@font-face
	{font-family:"Segoe UI Historic";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483153 33554434 6340736 0 1 0;}
@font-face
	{font-family:"Segoe UI Light";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1073683329 9 0 511 0;}
@font-face
	{font-family:"Segoe UI Semibold";
	panose-1:2 11 7 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1073683329 9 0 511 0;}
@font-face
	{font-family:"Segoe UI Semilight";
	panose-1:2 11 4 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-469750017 -1073683329 9 0 511 0;}
@font-face
	{font-family:"Segoe UI Symbol";
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483165 302055407 262144 0 1 0;}
@font-face
	{font-family:"Segoe UI Variable Small Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semilig";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Small";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Small Semibol";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Text Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semiligh";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Text";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Display Light";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semil";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Display";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"Segoe UI Variable Display Semib";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 11 0 0 415 0;}
@font-face
	{font-family:"\@SimSun";
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:515 680460288 22 0 262145 0;}
@font-face
	{font-family:NSimSun;
	panose-1:2 1 6 9 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:515 680460288 22 0 262145 0;}
@font-face
	{font-family:"\@NSimSun";
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:515 680460288 22 0 262145 0;}
@font-face
	{font-family:SimSun-ExtB;
	panose-1:2 1 6 9 6 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 168689664 16 0 262145 0;}
@font-face
	{font-family:"\@SimSun-ExtB";
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 168689664 16 0 262145 0;}
@font-face
	{font-family:"Sitka Small";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Small Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Text";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Text Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Subheading";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Subheading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Heading";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Heading Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Display";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Display Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Banner";
	panose-1:2 0 5 5 0 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:"Sitka Banner Semibold";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610611985 1073750091 0 0 415 0;}
@font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520081665 -1073717157 41 0 66047 0;}
@font-face
	{font-family:"Trebuchet MS";
	panose-1:2 11 6 3 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:1671 0 0 0 159 0;}
@font-face
	{font-family:Webdings;
	panose-1:5 3 1 2 1 5 9 6 7 3;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"\@Yu Gothic";
	panose-1:2 11 4 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic UI";
	panose-1:2 11 5 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic UI";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic UI Semibold";
	panose-1:2 11 7 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semibold";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic Light";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic UI Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic UI Light";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic Medium";
	panose-1:2 11 5 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic Medium";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"Yu Gothic UI Semilight";
	panose-1:2 11 4 0 0 0 0 0 0 0;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:"\@Yu Gothic UI Semilight";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 717749759 22 0 131231 0;}
@font-face
	{font-family:MingLiU_HKSCS;
	panose-1:2 2 5 0 0 0 0 0 0 0;
	mso-font-alt:MingLiU_HKSCS;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1610611969 684719354 22 0 1048577 0;}
@font-face
	{font-family:"HoloLens MDL2 Assets";
	panose-1:5 10 1 2 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 268435456 0 0 1 0;}
@font-face
	{font-family:"Agency FB";
	panose-1:2 11 5 3 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Algerian;
	panose-1:4 2 7 5 4 10 2 6 7 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Arial Narrow";
	panose-1:2 11 6 6 2 2 2 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 2048 0 0 159 0;}
@font-face
	{font-family:"Arial Rounded MT Bold";
	panose-1:2 15 7 4 3 5 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Baskerville Old Face";
	panose-1:2 2 6 2 8 5 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bauhaus 93";
	panose-1:4 3 9 5 2 11 2 2 12 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bell MT";
	panose-1:2 2 5 3 6 3 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Berlin Sans FB";
	panose-1:2 14 6 2 2 5 2 2 3 6;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Berlin Sans FB Demi";
	panose-1:2 14 8 2 2 5 2 2 3 6;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bernard MT Condensed";
	panose-1:2 5 8 6 6 9 5 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Blackadder ITC";
	panose-1:4 2 5 5 5 16 7 2 13 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bodoni MT Black";
	panose-1:2 7 10 3 8 6 6 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bodoni MT Condensed";
	panose-1:2 7 6 6 8 6 6 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Bodoni MT Poster Compressed";
	panose-1:2 7 7 6 8 6 1 5 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 17 0;}
@font-face
	{font-family:"Book Antiqua";
	panose-1:2 4 6 2 5 3 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Bookman Old Style";
	panose-1:2 5 6 4 5 5 5 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Bookshelf Symbol 7";
	panose-1:5 1 1 1 1 1 1 1 1 1;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Bradley Hand ITC";
	panose-1:3 7 4 2 5 3 2 3 2 3;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Britannic Bold";
	panose-1:2 11 9 3 6 7 3 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Broadway;
	panose-1:4 4 9 5 8 11 2 2 5 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Brush Script MT";
	panose-1:3 6 8 2 4 4 6 7 3 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Californian FB";
	panose-1:2 7 4 3 6 8 11 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Calisto MT";
	panose-1:2 4 6 3 5 5 5 3 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Castellar;
	panose-1:2 10 4 2 6 4 6 1 3 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Centaur;
	panose-1:2 3 5 4 5 2 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Century Gothic";
	panose-1:2 11 5 2 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Century Schoolbook";
	panose-1:2 4 6 4 5 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Chiller;
	panose-1:4 2 4 4 3 16 7 2 6 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Colonna MT";
	panose-1:4 2 8 5 6 2 2 3 2 3;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Cooper Black";
	panose-1:2 8 9 4 4 3 11 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Copperplate Gothic Bold";
	panose-1:2 14 7 5 2 2 6 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Copperplate Gothic Light";
	panose-1:2 14 5 7 2 2 6 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Curlz MT";
	panose-1:4 4 4 4 5 7 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Dubai;
	panose-1:2 11 5 3 3 4 3 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147475353 -2147483648 8 0 65 0;}
@font-face
	{font-family:"Dubai Light";
	panose-1:2 11 3 3 3 4 3 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147475353 -2147483648 8 0 65 0;}
@font-face
	{font-family:"Dubai Medium";
	panose-1:2 11 6 3 3 4 3 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147475353 -2147483648 8 0 65 0;}
@font-face
	{font-family:"Edwardian Script ITC";
	panose-1:3 3 3 2 4 7 7 13 8 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Elephant;
	panose-1:2 2 9 4 9 5 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Engravers MT";
	panose-1:2 9 7 7 8 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Eras Bold ITC";
	panose-1:2 11 9 7 3 5 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Eras Demi ITC";
	panose-1:2 11 8 5 3 5 4 2 8 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Eras Light ITC";
	panose-1:2 11 4 2 3 5 4 2 8 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Eras Medium ITC";
	panose-1:2 11 6 2 3 5 4 2 8 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Felix Titling";
	panose-1:4 6 5 5 6 2 2 2 10 4;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Footlight MT Light";
	panose-1:2 4 6 2 6 3 10 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Forte;
	panose-1:3 6 9 2 4 5 2 7 2 3;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Franklin Gothic Book";
	panose-1:2 11 5 3 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Franklin Gothic Demi";
	panose-1:2 11 7 3 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Franklin Gothic Demi Cond";
	panose-1:2 11 7 6 3 4 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Franklin Gothic Heavy";
	panose-1:2 11 9 3 2 1 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Franklin Gothic Medium Cond";
	panose-1:2 11 6 6 3 4 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Freestyle Script";
	panose-1:3 8 4 2 3 2 5 11 4 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"French Script MT";
	panose-1:3 2 4 2 4 6 7 4 6 5;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Garamond;
	panose-1:2 2 4 4 3 3 1 1 8 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:Gigi;
	panose-1:4 4 5 4 6 16 7 2 13 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Gill Sans MT";
	panose-1:2 11 5 2 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Gill Sans MT Condensed";
	panose-1:2 11 5 6 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Gill Sans MT Ext Condensed Bold";
	panose-1:2 11 9 2 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Gill Sans Ultra Bold";
	panose-1:2 11 10 2 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Gill Sans Ultra Bold Condensed";
	panose-1:2 11 10 6 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Gloucester MT Extra Condensed";
	panose-1:2 3 8 8 2 6 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Goudy Old Style";
	panose-1:2 2 5 2 5 3 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Goudy Stout";
	panose-1:2 2 9 4 7 3 11 2 4 1;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Haettenschweiler;
	panose-1:2 11 7 6 4 9 2 6 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Harlow Solid Italic";
	panose-1:4 3 6 4 2 15 2 2 13 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Harrington;
	panose-1:4 4 5 5 5 10 2 2 7 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"High Tower Text";
	panose-1:2 4 5 2 5 5 6 3 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Imprint MT Shadow";
	panose-1:4 2 6 5 6 3 3 3 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Informal Roman";
	panose-1:3 6 4 2 3 4 6 11 2 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Jokerman;
	panose-1:4 9 6 5 6 13 6 2 7 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Juice ITC";
	panose-1:4 4 4 3 4 10 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Kristen ITC";
	panose-1:3 5 5 2 4 2 2 3 2 2;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Kunstler Script";
	panose-1:3 3 4 2 2 6 7 13 13 6;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Bright";
	panose-1:2 4 6 2 5 5 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Calligraphy";
	panose-1:3 1 1 1 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Fax";
	panose-1:2 6 6 2 5 5 5 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Handwriting";
	panose-1:3 1 1 1 1 1 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Lucida Sans";
	panose-1:2 11 6 2 4 5 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130662665 32891 8 0 159 0;}
@font-face
	{font-family:"Lucida Sans Typewriter";
	panose-1:2 11 5 9 3 5 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:fixed;
	mso-font-signature:16788359 0 8 0 65663 0;}
@font-face
	{font-family:Magneto;
	panose-1:4 3 8 5 5 8 2 2 13 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Maiandra GD";
	panose-1:2 14 5 2 3 3 8 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Matura MT Script Capitals";
	panose-1:3 2 8 2 6 6 2 7 2 2;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Mistral;
	panose-1:3 9 7 2 3 4 7 2 4 3;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"Modern No\. 20";
	panose-1:2 7 7 4 7 5 5 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Monotype Corsiva";
	panose-1:3 1 1 1 1 2 1 1 1 1;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:647 0 0 0 159 0;}
@font-face
	{font-family:"MS Outlook";
	panose-1:5 1 1 0 1 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"MS Reference Sans Serif";
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:536871559 0 0 0 415 0;}
@font-face
	{font-family:"MS Reference Specialty";
	panose-1:5 0 5 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Niagara Engraved";
	panose-1:4 2 5 2 7 7 3 3 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Niagara Solid";
	panose-1:4 2 5 2 7 7 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"OCR A Extended";
	panose-1:2 1 5 9 2 1 2 1 3 3;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Old English Text MT";
	panose-1:3 4 9 2 4 5 8 3 8 6;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Onyx;
	panose-1:4 5 6 2 8 7 2 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Palace Script MT";
	panose-1:3 3 3 2 2 6 7 12 11 5;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Papyrus;
	panose-1:3 7 5 2 6 5 2 3 2 5;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Parchment;
	panose-1:3 4 6 2 4 7 8 4 8 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Perpetua;
	panose-1:2 2 5 2 6 4 1 2 3 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Perpetua Titling MT";
	panose-1:2 2 5 2 6 5 5 2 8 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Playbill;
	panose-1:4 5 6 3 10 6 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Poor Richard";
	panose-1:2 8 5 2 5 5 5 2 7 2;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Pristina;
	panose-1:3 6 4 2 4 4 6 8 2 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Rage Italic";
	panose-1:3 7 5 2 4 5 7 7 3 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Ravie;
	panose-1:4 4 8 5 5 8 9 2 6 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Rockwell;
	panose-1:2 6 6 3 2 2 5 2 4 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Rockwell Condensed";
	panose-1:2 6 6 3 5 4 5 2 1 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Rockwell Extra Bold";
	panose-1:2 6 9 3 4 5 5 2 4 3;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Script MT Bold";
	panose-1:3 4 6 2 4 6 7 8 9 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Showcard Gothic";
	panose-1:4 2 9 4 2 1 2 2 6 4;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Snap ITC";
	panose-1:4 4 10 7 6 10 2 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Stencil;
	panose-1:4 4 9 5 13 8 2 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Tempus Sans ITC";
	panose-1:4 2 4 4 3 13 7 2 2 2;
	mso-font-charset:0;
	mso-generic-font-family:decorative;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Tw Cen MT";
	panose-1:2 11 6 2 2 1 4 2 6 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Tw Cen MT Condensed";
	panose-1:2 11 6 6 2 1 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Tw Cen MT Condensed Extra Bold";
	panose-1:2 11 8 3 2 2 2 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 3 0;}
@font-face
	{font-family:"Viner Hand ITC";
	panose-1:3 7 5 2 3 5 2 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:Vivaldi;
	panose-1:3 2 6 2 5 5 6 9 8 4;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Vladimir Script";
	panose-1:3 5 4 2 4 4 7 7 3 5;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Wide Latin";
	panose-1:2 10 10 7 5 5 5 2 4 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"Wingdings 2";
	panose-1:5 2 1 2 1 5 7 7 7 7;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Wingdings 3";
	panose-1:5 4 1 2 1 8 7 7 7 7;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"HP Simplified";
	panose-1:2 11 6 4 2 2 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612561 1342185563 0 0 147 0;}
@font-face
	{font-family:"HP Simplified Light";
	panose-1:2 11 4 4 2 2 4 2 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612561 1342185563 0 0 147 0;}
@font-face
	{font-family:"HP Simplified Jpan Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 953150970 18 0 1442207 0;}
@font-face
	{font-family:"\@HP Simplified Jpan Light";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 953150970 18 0 1442207 0;}
@font-face
	{font-family:"HP Simplified Jpan";
	panose-1:2 11 5 0 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 953150970 18 0 1442207 0;}
@font-face
	{font-family:"\@HP Simplified Jpan";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 953150970 18 0 1442207 0;}
@font-face
	{font-family:"HP Simplified Hans Light";
	panose-1:2 11 3 0 0 0 0 0 0 0;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262429 0;}
@font-face
	{font-family:"\@HP Simplified Hans Light";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262429 0;}
@font-face
	{font-family:"HP Simplified Hans";
	panose-1:2 11 5 0 0 0 0 0 0 0;
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262429 0;}
@font-face
	{font-family:"\@HP Simplified Hans";
	mso-font-charset:134;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612033 953122042 22 0 262429 0;}
@font-face
	{font-family:ZWAdobeF;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:536881799 0 0 0 511 0;}
@font-face
	{font-family:"Euro Sign";
	panose-1:2 11 6 3 2 2 1 2 1 1;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 2 0 0 1 0;}
@font-face
	{font-family:"MT Extra";
	panose-1:5 5 1 2 1 2 5 2 2 2;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:SimSun-ExtG;
	panose-1:2 1 6 9 6 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 168689664 16 0 262145 0;}
@font-face
	{font-family:"\@SimSun-ExtG";
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:3 168689664 16 0 262145 0;}
@font-face
	{font-family:"\3105\5B57\55E8\6CE8\97F3\6A19\6977 Regular";
	panose-1:2 2 4 0 0 0 0 0 0 0;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2147483485 449805434 22 0 1048576 0;}
@font-face
	{font-family:"\@\3105\5B57\55E8\6CE8\97F3\6A19\6977 Regular";
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2147483485 449805434 22 0 1048576 0;}
@font-face
	{font-family:"Cascadia Code ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Code Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Code SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Code";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Code SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Mono ExtraLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Mono Light";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Mono SemiLight";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Mono";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:"Cascadia Mono SemiBold";
	panose-1:2 11 6 9 2 0 0 2 0 4;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1593824513 -1040123397 262176 0 511 0;}
@font-face
	{font-family:Lato;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:\6A19\6977\9AD4-\7E41;
	mso-font-alt:"Microsoft JhengHei";
	mso-font-charset:136;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-2147482909 953154938 22 0 1048589 0;}
@font-face
	{font-family:Ambiant;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:Scala;
	mso-font-alt:Arial;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:1 1073750088 0 0 273 0;}
@font-face
	{font-family:\83EF\5EB7\4EFF\5B8B\9AD4W2;
	mso-font-alt:"\5FAE\8EDF\6B63\9ED1\9AD4 Light";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:0 671684608 22 0 1048576 0;}
@font-face
	{font-family:minorEastAsia;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:minorBidi;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"New MingLiu";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:"\6A19\6977\9AD4i\.";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:TimesNewRomanPSMT;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:HL01;
	mso-font-alt:"Arial Narrow";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:\83EF\5EB7\4E2D\660E\9AD4;
	mso-font-alt:"Microsoft JhengHei";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"Century Schoolbook \(OTF\) Italic";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:ATC-6a195b8b*+Times-2;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Microsoft JhengHei";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:"monospace\!important";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:inherit;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:0 0 0 0 0 0;}
@font-face
	{font-family:NimbusRomNo9L-Regu;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:DFMingStd-W5;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:DFHeiStd-W7;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:TimesNewRomanPS-ItalicMT;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Times New Roman";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:131 134742016 16 0 1048585 0;}
@font-face
	{font-family:"MS PMincho";
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:\83EF\5EB7\6A19\5B8B\9AD4;
	mso-font-alt:"Microsoft JhengHei";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:HL20;
	mso-font-alt:Vrinda;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:"\@\83EF\5EB7\8D85\7279\5713\9AD4\(P\)";
	mso-font-alt:"\@Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\@Batang";
	panose-1:2 3 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:BatangChe;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@BatangChe";
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:Gungsuh;
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@Gungsuh";
	mso-font-charset:129;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:GungsuhChe;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@GungsuhChe";
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:DaunPenh;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:3 0 65536 0 1 0;}
@font-face
	{font-family:DokChampa;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:50331651 0 0 0 65537 0;}
@font-face
	{font-family:Euphemia;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483537 74 8192 0 1 0;}
@font-face
	{font-family:Vani;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:2097155 0 0 0 1 0;}
@font-face
	{font-family:"\@Gulim";
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:GulimChe;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@GulimChe";
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@Dotum";
	panose-1:2 11 6 0 0 1 1 1 1 1;
	mso-font-charset:129;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:DotumChe;
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"\@DotumChe";
	mso-font-charset:129;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1342176593 1775729915 48 0 524447 0;}
@font-face
	{font-family:"Iskoola Pota";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 512 0 1 0;}
@font-face
	{font-family:Kalinga;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:524291 0 0 0 1 0;}
@font-face
	{font-family:Kartika;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:8388611 0 0 0 1 0;}
@font-face
	{font-family:"Khmer UI";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483601 8266 65536 0 1 0;}
@font-face
	{font-family:"Lao UI";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:33554435 0 0 0 1 0;}
@font-face
	{font-family:"\@MS Mincho";
	panose-1:2 2 6 9 4 2 5 8 3 4;
	mso-font-charset:128;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:"\@MS PMincho";
	mso-font-charset:128;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536870145 1791491579 18 0 131231 0;}
@font-face
	{font-family:Nyala;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610612625 0 2048 0 147 0;}
@font-face
	{font-family:"Plantagenet Cherokee";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:3 0 4096 0 1 0;}
@font-face
	{font-family:"Shonar Bangla";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:65539 0 0 0 1 0;}
@font-face
	{font-family:Aparajita;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:32771 0 0 0 1 0;}
@font-face
	{font-family:Gisha;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147481593 1073741890 0 0 33 0;}
@font-face
	{font-family:Kokila;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:32771 0 0 0 1 0;}
@font-face
	{font-family:Leelawadee;
	panose-1:2 11 5 2 4 2 4 2 2 3;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130706257 1073750091 0 0 65537 0;}
@font-face
	{font-family:"Microsoft Uighur";
	panose-1:2 0 0 0 0 0 0 0 0 0;
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:8195 -2147483648 8 0 65 0;}
@font-face
	{font-family:MoolBoran;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483633 8266 65536 0 1 0;}
@font-face
	{font-family:Utsaah;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:32771 0 0 0 1 0;}
@font-face
	{font-family:Vijaya;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:1048579 0 0 0 1 0;}
@font-face
	{font-family:Andalus;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:8195 -2147483648 8 0 65 0;}
@font-face
	{font-family:"Arabic Typesetting";
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:-1610604433 -1073741824 8 0 211 0;}
@font-face
	{font-family:"Simplified Arabic";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:8195 0 0 0 65 0;}
@font-face
	{font-family:"Simplified Arabic Fixed";
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:8195 0 0 0 65 0;}
@font-face
	{font-family:"Sakkal Majalla";
	mso-font-charset:0;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:-1610604417 -1073733557 8 0 211 0;}
@font-face
	{font-family:"Traditional Arabic";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:8195 -2147483648 8 0 65 0;}
@font-face
	{font-family:Aharoni;
	mso-font-charset:177;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:David;
	mso-font-charset:177;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:FrankRuehl;
	mso-font-charset:177;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:"Levenim MT";
	mso-font-charset:177;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:Miriam;
	mso-font-charset:177;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:"Miriam Fixed";
	mso-font-charset:177;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:Narkisim;
	mso-font-charset:177;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:Rod;
	mso-font-charset:177;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:2049 0 0 0 32 0;}
@font-face
	{font-family:FangSong;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482945 953122042 22 0 262145 0;}
@font-face
	{font-family:"\@FangSong";
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482945 953122042 22 0 262145 0;}
@font-face
	{font-family:"\@SimHei";
	panose-1:2 1 6 0 3 1 1 1 1 1;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482945 953122042 22 0 262145 0;}
@font-face
	{font-family:KaiTi;
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482945 953122042 22 0 262145 0;}
@font-face
	{font-family:"\@KaiTi";
	mso-font-charset:134;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147482945 953122042 22 0 262145 0;}
@font-face
	{font-family:AngsanaUPC;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2130706429 0 0 0 65537 0;}
@font-face
	{font-family:"Browallia New";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130706429 0 0 0 65537 0;}
@font-face
	{font-family:BrowalliaUPC;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130706429 0 0 0 65537 0;}
@font-face
	{font-family:CordiaUPC;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2130706429 0 0 0 65537 0;}
@font-face
	{font-family:DilleniaUPC;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2130706393 2 0 0 65537 0;}
@font-face
	{font-family:EucrosiaUPC;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-2130706393 2 0 0 65537 0;}
@font-face
	{font-family:FreesiaUPC;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:16777223 2 0 0 65537 0;}
@font-face
	{font-family:IrisUPC;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:16777223 2 0 0 65537 0;}
@font-face
	{font-family:JasmineUPC;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:16777223 2 0 0 65537 0;}
@font-face
	{font-family:KodchiangUPC;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:16777223 2 0 0 65537 0;}
@font-face
	{font-family:LilyUPC;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:16777223 2 0 0 65537 0;}
@font-face
	{font-family:"\@Arial Unicode MS";
	panose-1:2 11 6 4 2 2 2 2 2 4;
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-134238209 -371195905 63 0 4129279 0;}
@font-face
	{font-family:Meiryo;
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520027393 -355991553 65554 0 131231 0;}
@font-face
	{font-family:"\@Meiryo";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520027393 -355991553 65554 0 131231 0;}
@font-face
	{font-family:"Meiryo UI";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520027393 -355991553 65554 0 131231 0;}
@font-face
	{font-family:"\@Meiryo UI";
	mso-font-charset:128;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-520027393 -355991553 65554 0 131231 0;}
@font-face
	{font-family:"Albertus Medium";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Albertus;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Albertus Extra Bold";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Avant Garde Gothic";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Avant Garde Gothic Demi";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Bookman Light";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Bookman Demi";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"CG Omega";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"CG Times";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Zapf Chancery";
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Clarendon;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Clarendon Condensed";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Clarendon Extended";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Coronet;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:CourierPS;
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"ITC Zapf Dingbats";
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:"Helvetica Narrow";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Letter Gothic";
	mso-font-charset:0;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Marigold;
	mso-font-charset:0;
	mso-generic-font-family:script;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"New Century Schoolbook";
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Antique Olive";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Antique Olive Compact";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Palatino;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:SymbolPS;
	mso-font-charset:2;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
@font-face
	{font-family:Times;
	panose-1:2 2 6 3 5 4 5 2 3 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:Univers;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:"Univers Condensed";
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:7 0 0 0 147 0;}
@font-face
	{font-family:\83EF\5EB7\4E2D\7279\5713\9AD4;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\@\83EF\5EB7\4E2D\7279\5713\9AD4";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\83EF\5EB7\4E2D\7279\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\@\83EF\5EB7\4E2D\7279\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:\83EF\5EB7\7D30\5713\9AD4;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\@\83EF\5EB7\7D30\5713\9AD4";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\83EF\5EB7\7D30\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\@\83EF\5EB7\7D30\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:\83EF\5EB7\7C97\5713\9AD4;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\@\83EF\5EB7\7C97\5713\9AD4";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\83EF\5EB7\7C97\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:"\@\83EF\5EB7\7C97\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-1610612161 978295864 22 0 1048577 0;}
@font-face
	{font-family:\83EF\5EB7\65B0\7279\5713\9AD4;
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\@\83EF\5EB7\65B0\7279\5713\9AD4";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\83EF\5EB7\65B0\7279\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\@\83EF\5EB7\65B0\7279\5713\9AD4\(P\)";
	mso-font-charset:136;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-2147483647 671684608 22 0 1048576 0;}
@font-face
	{font-family:"\6587\9F0E\6A19\6E96\6977\9AD42\.";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:HL10;
	mso-font-alt:Vrinda;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:3 0 0 0 1 0;}
@font-face
	{font-family:ATC-7d309ed1*+Times;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:"\6A19\6977\9AD4i\.\6C2C\.\.";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:\83EF\5EB7\4E2D\9ED1\9AD4;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:modern;
	mso-font-pitch:fixed;
	mso-font-signature:0 671684608 22 0 1048576 0;}
@font-face
	{font-family:DFBiaoSong-B5;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:PMingLiU;
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:\6A19\5B8B+Time;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:\6A19\9ED1+Times\5168;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:\5357\4E00\4E2D\7D30\660E\9AD4\5B57;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:ATC-6a196977*P+Times*5168;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:ID\6578\5B78;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:"Adobe \660E\9AD4 Std L";
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:roman;
	mso-font-format:other;
	mso-font-pitch:variable;
	mso-font-signature:0 437197056 22 0 1179653 0;}
@font-face
	{font-family:ATC-6a199ed1*+Times*5168;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:nanimath90;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:ATC-6a195b8b*+Time;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:"Arial Unicode MS";
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:ATC-83ef5eb74eff5b8b*+Time;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:ID\6578\5B78;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
@font-face
	{font-family:ATC-6a195b8b*+Times;
	panose-1:0 0 0 0 0 0 0 0 0 0;
	mso-font-alt:ID\6578\5B78;
	mso-font-charset:136;
	mso-generic-font-family:auto;
	mso-font-format:other;
	mso-font-pitch:auto;
	mso-font-signature:1 134742016 16 0 1048576 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
h1
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-link:"\6A19\984C 1 \5B57\5143";
	mso-style-next:\5167\6587;
	margin-top:9.0pt;
	margin-right:0cm;
	margin-bottom:9.0pt;
	margin-left:0cm;
	line-height:300%;
	mso-pagination:widow-orphan;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:26.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	mso-font-kerning:26.0pt;
	font-weight:bold;}
h2
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-link:"\6A19\984C 2 \5B57\5143";
	mso-margin-top-alt:auto;
	margin-right:0cm;
	mso-margin-bottom-alt:auto;
	margin-left:0cm;
	mso-pagination:widow-orphan;
	mso-outline-level:2;
	font-size:18.0pt;
	font-family:"Times New Roman",serif;
	font-weight:bold;}
h3
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-link:"\6A19\984C 3 \5B57\5143";
	mso-margin-top-alt:auto;
	margin-right:0cm;
	mso-margin-bottom-alt:auto;
	margin-left:0cm;
	mso-pagination:widow-orphan;
	mso-outline-level:3;
	font-size:13.5pt;
	font-family:"Times New Roman",serif;
	font-weight:bold;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{mso-style-priority:99;
	mso-style-link:"\9801\9996 \5B57\5143";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:center 207.65pt right 415.3pt;
	layout-grid-mode:char;
	font-size:10.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{mso-style-priority:99;
	mso-style-link:"\9801\5C3E \5B57\5143";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	tab-stops:center 207.65pt right 415.3pt;
	layout-grid-mode:char;
	font-size:10.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
a:link, span.MsoHyperlink
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:blue;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{mso-style-noshow:yes;
	mso-style-priority:99;
	color:purple;
	text-decoration:underline;
	text-underline:single;}
p
	{mso-style-noshow:yes;
	mso-style-priority:99;
	mso-margin-top-alt:auto;
	margin-right:0cm;
	mso-margin-bottom-alt:auto;
	margin-left:0cm;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{mso-style-noshow:yes;
	mso-style-priority:34;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:0cm;
	margin-left:24.0pt;
	margin-bottom:.0001pt;
	mso-para-margin-top:0cm;
	mso-para-margin-right:0cm;
	mso-para-margin-bottom:0cm;
	mso-para-margin-left:2.0gd;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
span.1
	{mso-style-name:"\6A19\984C 1 \5B57\5143";
	mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:"\6A19\984C 1";
	mso-ansi-font-size:26.0pt;
	mso-bidi-font-size:26.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	mso-font-kerning:26.0pt;
	font-weight:bold;}
span.2
	{mso-style-name:"\6A19\984C 2 \5B57\5143";
	mso-style-noshow:yes;
	mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:"\6A19\984C 2";
	mso-ansi-font-size:24.0pt;
	mso-bidi-font-size:24.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	font-weight:bold;}
span.3
	{mso-style-name:"\6A19\984C 3 \5B57\5143";
	mso-style-noshow:yes;
	mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:"\6A19\984C 3";
	mso-ansi-font-size:18.0pt;
	mso-bidi-font-size:18.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-ascii-theme-font:major-latin;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:major-fareast;
	mso-hansi-font-family:Cambria;
	mso-hansi-theme-font:major-latin;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:major-bidi;
	font-weight:bold;}
p.msonormal0, li.msonormal0, div.msonormal0
	{mso-style-name:msonormal;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-unhide:no;
	mso-margin-top-alt:auto;
	margin-right:0cm;
	mso-margin-bottom-alt:auto;
	margin-left:0cm;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman",serif;
	mso-fareast-font-family:PMingLiU;
	mso-fareast-theme-font:minor-fareast;}
span.a
	{mso-style-name:"\9801\9996 \5B57\5143";
	mso-style-priority:99;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:\9801\9996;}
span.a0
	{mso-style-name:"\9801\5C3E \5B57\5143";
	mso-style-priority:99;
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-link:\9801\5C3E;}
span.msoIns
	{mso-style-type:export-only;
	mso-style-name:"";
	text-decoration:underline;
	text-underline:single;
	color:teal;}
span.msoDel
	{mso-style-type:export-only;
	mso-style-name:"";
	text-decoration:line-through;
	color:red;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	font-size:10.0pt;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:"Times New Roman";
	mso-hansi-font-family:"Times New Roman";
	mso-font-kerning:0pt;}
 /* Page Definitions */
 @page
	{mso-footnote-separator:url("publication.files/header.html") fs;
	mso-footnote-continuation-separator:url("publication.files/header.html") fcs;
	mso-endnote-separator:url("publication.files/header.html") es;
	mso-endnote-continuation-separator:url("publication.files/header.html") ecs;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	mso-header-margin:42.55pt;
	mso-footer-margin:49.6pt;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 @list l0
	{mso-list-id:243489851;
	mso-list-type:hybrid;
	mso-list-template-ids:-1635469598 621204586 67698691 67698693 67698689 67698691 67698693 67698689 67698691 67698693;}
@list l0:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F06F;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:24.0pt;
	text-indent:-24.0pt;
	mso-ansi-font-size:9.0pt;
	font-family:Wingdings;}
@list l0:level2
	{mso-level-number-format:bullet;
	mso-level-text:\F06E;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:48.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F075;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:72.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F06C;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:96.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F06E;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:120.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F075;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:144.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F06C;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:168.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F06E;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:192.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l0:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F075;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:216.0pt;
	text-indent:-24.0pt;
	font-family:Wingdings;}
@list l1
	{mso-list-id:434986027;
	mso-list-template-ids:1966401434;}
@list l1:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l1:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l1:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l1:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2
	{mso-list-id:932205725;
	mso-list-template-ids:-1589061142;}
@list l2:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l2:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l2:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l2:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3
	{mso-list-id:1154906691;
	mso-list-template-ids:1462392788;}
@list l3:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l3:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l3:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l3:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4
	{mso-list-id:1223909008;
	mso-list-template-ids:264036496;}
@list l4:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l4:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l4:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l4:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5
	{mso-list-id:1441872001;
	mso-list-template-ids:-1210936822;}
@list l5:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l5:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l5:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l5:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6
	{mso-list-id:1823736622;
	mso-list-template-ids:1352465596;}
@list l6:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l6:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l6:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l6:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7
	{mso-list-id:2081052441;
	mso-list-template-ids:1504723202;}
@list l7:level1
	{mso-level-number-format:bullet;
	mso-level-text:\F0B7;
	mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Symbol;}
@list l7:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:"Courier New";
	mso-bidi-font-family:"Times New Roman";}
@list l7:level3
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level4
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level5
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level6
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:216.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level7
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:252.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level8
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:288.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
@list l7:level9
	{mso-level-number-format:bullet;
	mso-level-text:\F0A7;
	mso-level-tab-stop:324.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;
	mso-ansi-font-size:10.0pt;
	font-family:Wingdings;}
ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:\8868\683C\5167\6587;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman",serif;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="2049"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body bgcolor=white lang=ZH-TW link=blue vlink=purple style='tab-interval:24.0pt'>

<div class=WordSection1>

<h3><span lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'><a href="index.html">Home</a> | <a href="lab.html">Lab</a> |
<a href="publication.html">Publication</a> | <a href="teaching.html"><span
style='mso-fareast-font-family:PMingLiU;mso-fareast-theme-font:minor-fareast'>Teaching</span></a>
| <a href="resources.html">Resources</a><o:p></o:p></span></h3>

<h3 align=center style='text-align:center'><span lang=EN-US style='font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>

<hr size=2 width="100%" align=center>

</span></h3>

<h2><a name=top><span lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>My publication </span></a><span style='mso-bookmark:top'><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'>sorted by topic</span></span><span style='mso-bookmark:top'></span><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#generation">Music generation</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#emotion">Music and emotion</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#classification">Music/sound classification and auto-tagging</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#separation">Source separation</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#transcription">Music transcription</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#structure">Structure analysis</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#performance">Performance/expressivity</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#recommendation">Recommendation</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a href="#video">Music
and video</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#retrieval">Retrieval</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#editorial">Editorial</a><o:p></o:p></span></h2>

<h2 style='margin-top:5.0pt;margin-right:0cm;margin-bottom:6.0pt;margin-left:
24.1pt;mso-para-margin-top:5.0pt;mso-para-margin-right:0cm;mso-para-margin-bottom:
.5gd;mso-para-margin-left:24.1pt;text-indent:-24.1pt;mso-char-indent-count:
-2.01;mso-list:l0 level1 lfo1'><![if !supportLists]><span lang=EN-US
style='font-size:9.0pt;mso-bidi-font-size:12.0pt;font-family:Wingdings;
mso-fareast-font-family:Wingdings;mso-bidi-font-family:Wingdings;font-weight:
normal;mso-bidi-font-weight:bold'><span style='mso-list:Ignore'>o<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'><a
href="#others">Others</a><o:p></o:p></span></h2>

<h2><span lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(</span><span lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";color:red'>NOTE</span><span
lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'>: Please visit <a
href="https://scholar.google.com/citations?hl=zh-TW&amp;user=OL-XGxcAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">here</a>
for the alternative version in </span><span lang=EN-US style='font-size:12.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>chronological
order</span><span lang=EN-US style='font-size:12.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>)<o:p></o:p></span></h2>

<h2 align=center style='text-align:center'><span lang=EN-US style='font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>

<hr size=2 width="100%" align=center>

</span></h2>

<h3><a name=generation><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Music
Generation</span></a><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'> </span><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to <a href="#top">top</a>)</span><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Dinh-Viet-Toan Le and Yi-Hsuan
     Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>METEOR: Melody-aware
     texture-controllable symbolic orchestral music generation</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/2409.11753</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, September </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>2024.<br>
     (<a href="https://arxiv.org/abs/2409.11753">paper</a>, <a
     href="https://dinhviettoanle.github.io/meteor/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yen-Tung Yeh, Yu-Hua Chen,
     Yuan-Chiao Cheng, Jui-Te Wu, Jun-Jie Fu, Yi-Fan Yeh, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>DDSP Guitar Amp:
     Interpretable guitar amplifier modeling</b>,&quot; <br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2025 (<b><span style='color:brown'>ICASSP&#8217;25</span></b>),
     accepted for publication.<br>
     (<a href="https://arxiv.org/abs/2408.11405">paper</a>, <a
     href="https://ytsrt66589.github.io/ddspGuitarAmp_Demo/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chon In Leong, I-Ling Chung, Kin
     Fong Chao, Jun-You Wang, Yi-Hsuan Yang, and Jyh-Shing Roger Jan,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Music2Fail: Transfer music to
     failed recorder style</b>,&quot;<br>
     in Proc. Asia Pacific Signal and Information Processing Association Annual
     Summit and Conf. 2024 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>APSIPA ASC&#8217;24</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2411.18075">paper</a>, <a
     href="https://navi0105.github.io/demo/music2fail/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Yuan-Chiao Cheng,
     Yen-Tung Yeh, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, and Yi-Hsuan
     Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Demo of zero-shot guitar
     amplifier modelling: Enhancing modeling with hyper neural networks</b>,&quot;
     <br>
     Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR-LBD&#8217;24</span></b>), <br>
     late-breaking and demo paper, 2024.<br>
     (<a href="https://arxiv.org/abs/2410.04702">paper</a>, demo)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yen-Tung Yeh, Wen-Yi Hsiao, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>PyNeuralFx: A Python package
     for neural audio effect modeling</b>,&quot; <br>
     Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR-LBD&#8217;24</span></b>), <br>
     late-breaking and demo paper, 2024.<br>
     (<a href="https://arxiv.org/abs/2408.06053">paper</a>, <a
     href="https://github.com/ytsrt66589/pyneuralfx">toolkit</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jingyue Huang, Ke Chen, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Emotion-driven piano music
     generation via two-stage disentanglement and functional representation</b>,&quot;
     <br>
     in Proc. Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR</span></b>), 2024.<br>
     (<a href="https://arxiv.org/abs/2407.20955">paper</a>, <a
     href="https://github.com/Yuer867/EMO-Disentanger">code</a>, <a
     href="https://zenodo.org/records/13122742">data1</a>, <a
     href="https://zenodo.org/records/13167761">data2</a>, <a
     href="https://emo-disentanger.github.io/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yun-Han Lan, Wen-Yi Hsiao,
     Hao-Chung Cheng, Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>MusiConGen: Rhythm and chord
     control for Transformer-based text-to-music generation</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR</span></b>), 2024.<br>
     (<a href="https://arxiv.org/abs/2407.15060">paper</a>, <a
     href="https://github.com/Cyan0731/MusiConGen">code</a>, <a
     href="https://musicongen.github.io/musicongen_demo/">demo</a>, <a
     href="https://huggingface.co/spaces/fffiloni/MusiConGen">huggingface</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Fang-Duo Tsai, Shih-Lun Wu, Haven
     Kim, Bo-Yu Chen, Hao-Chung Cheng, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Audio Prompt Adapter:
     Unleashing music editing abilities for text-to-music with lightweight
     finetuning</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR</span></b>), 2024.<br>
     (<a href="https://arxiv.org/abs/2407.16564">paper</a>, <a
     href="https://github.com/fundwotsai2001/AP-adapter">code</a>, <a
     href="https://ap-adapter.notionlinker.com/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chih-Pin Tan, Hsin Ai, Yi-Hsin
     Chang, Shuen-Huei Guan, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>PiCoGen2: Piano cover
     generation with transfer learning approach and weakly aligned data</b>,&#8221;
     <br>
     in Proc. Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR</span></b>), 2024.<br>
     (<a href="https://arxiv.org/abs/2408.01551">paper</a>, <a
     href="https://github.com/tanchihpin0517/PiCoGen/tree/v2">code</a>, <a
     href="https://tanchihpin0517.github.io/PiCoGen/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Yen-Tung Yeh,
     Yuan-Chiao Cheng, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Towards zero-shot amplifier
     modeling: One-to-many amplifier modeling via tone embedding control</b>,&quot;
     <br>
     in Proc. Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR</span></b>), 2024.<br>
     (<a href="https://arxiv.org/abs/2407.10646">paper</a>, <a
     href="https://ss12f32v.github.io/Guitar-Zero-Shot/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yen-Tung Yeh, Wen-Yi Hsiao and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Hyper recurrent neural
     network: Condition mechanisms for black-box audio effect modeling</b>,&quot;
     <br>
     in Proc. Int. Conf. Digital Audio Effects (<b><span style='color:brown'>DAFx</span></b>),
     2024.<br>
     (<a href="https://arxiv.org/abs/2408.04829">paper</a>, <a
     href="https://github.com/ytsrt66589/pyneuralfx">code</a>, <a
     href="https://yytung.notion.site/HyperRNN">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Woosung Choi,
     Wei-Hsiang Liao, Marco Mart&iacute;nez-Ram&iacute;rez, Kin Wai Cheuk, Yuki
     Mitsufuji, Jyh-Shing Roger Jang and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Improving unsupervised
     clean-to-rendered guitar tone transformation using GANs and integrated
     unaligned clean data</b>,&quot; <br>
     in Proc. Int. Conf. Digital Audio Effects (<b><span style='color:brown'>DAFx</span></b>),
     2024.<br>
     (<a href="https://arxiv.org/abs/2406.15751">paper</a>, <a
     href="https://yu-hua.notion.site/Demo-Pages-007b84da1a4f411090a1c9243602a9ab">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Ying-Shuo Lee, Yueh-Po Peng,
     Jui-Te Wu, Ming Cheng, Li Su and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Distortion recovery: A
     two-stage method for guitar effect removal</b>,&quot; <br>
     in Proc. Int. Conf. Digital Audio Effects (<b><span style='color:brown'>DAFx</span></b>),
     2024.<br>
     (<a href="https://arxiv.org/abs/2407.16639">paper</a>, <a
     href="https://github.com/y10ab1/guitar_effect_removal">code</a>, <a
     href="https://zenodo.org/records/12658984">data</a>, <a
     href="https://y10ab1.github.io/guitar_effect_removal/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chih-Pin Tan, Shuen-Huei Guan,
     and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>PiCoGen: Generate piano
     covers with a two-stage approach</b>,&quot; <br>
     in Proc. ACM Int. Conf. Multimedia Retrieval (<b><span style='color:brown'>ICMR</span></b>),
     <br>
     short paper, 2024.<br>
     (<a href="https://arxiv.org/abs/2407.20883">paper</a>, <a
     href="https://tanchihpin0517.github.io/PiCoGen/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jingyue Huang and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Emotion-driven melody
     harmonization via melodic variation and functional representation</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/2407.20176</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>July
     2024.<br>
     (<a href="https://arxiv.org/abs/2407.20176">paper</a>, <a
     href="https://github.com/Yuer867/EMO_Harmonizer">code</a>, <a
     href="https://yuer867.github.io/emo_harmonizer/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Woosung Choi,
     WeiHsiang Liao, Marco A. Martinez Ramirez, Kin Wai Cheuk, Yi-Hsuan Yang,
     and Yuki Mitsufuji, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Neural amplifier modelling
     with several GAN variants</b>,&quot; <br>
     Int. Society for Music Information Retrieval Conf. (<b><span
     style='color:brown'>ISMIR-LBD&#8217;23</span></b>), <br>
     late-breaking and demo paper, 2023.<br>
     (<a href="https://ismir2023program.ismir.net/lbd_364.html">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Shih-Lun Wu and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Compose &amp; Embellish:
     Well-structured piano performance generation via a two-stage approach</b>,&quot;
     <br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2023 (<b><span style='color:brown'>ICASSP&#8217;23</span></b>).<br>
     (<a href="https://arxiv.org/abs/2209.08212">paper</a>, <a
     href="https://github.com/slSeanWU/Compose_and_Embellish">code</a>, <a
     href="https://drive.google.com/drive/folders/10r_uPHMT4mxCoA3OrLyDE3q-QXzUl80F">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Shih-Lun Wu and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>MuseMorphose: Full-song and
     fine-grained piano music style transfer with just one Transformer VAE</b>,&quot;
     <br>
     in: IEEE/ACM Transactions on Audio, Speech, and Language Processing (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>TASLP</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>), vol. 31, pp. 1953-1967, May
     2023.<br>
     (<a href="https://arxiv.org/abs/2105.04090">paper</a>, <a
     href="https://github.com/YatingMusic/MuseMorphose">code</a>, <a
     href="https://slseanwu.github.io/site-musemorphose/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yueh-Kao Wu, Ching-Yu Chiu, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>JukeDrummer: Conditional
     beat-aware drum accompaniment generation in the audio domain using
     Transformer VQ-VAE</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2022 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>22</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 193-200.<br>
     (<a href="https://arxiv.org/abs/2210.06007">paper</a>, <a
     href="https://legoodmanner.github.io/jukedrummer-demo/">demo</a>, <a
     href="https://github.com/legoodmanner/jukedrummer">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yen-Tung Yeh, Bo-Yu Chen, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Exploiting pre-trained
     feature networks for generative adversarial networks in audio-domain loop
     generation</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2022 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>22</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2209.01751.pdf">paper</a>, <a
     href="https://arthurddd.github.io/PjLoopGAN/">demo</a>, <a
     href="https://github.com/Arthurddd/pjloop-gan">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chih-Pin Tan, Wen-Yu Su, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Melody infilling with
     user-provided structural context</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2022 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>22</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2210.02829.pdf">paper</a>, <a
     href="https://tanchihpin0517.github.io/structure-aware_infilling/">demo</a>,
     <a href="https://github.com/tanchihpin0517/structure-aware_infilling">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Da-Yi Wu, Wen-Yi Hsiao, Fu-Rong
     Yang, Oscar Friedman, Warren Jackson, Scott Bruzenak, Yi-Wen Liu, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>DDSP-based singing vocoders:
     A new subtractive-based synthesizer and a comprehensive evaluation</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2022 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>22</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 76-83.<br>
     (<a href="https://arxiv.org/pdf/2208.04756.pdf">paper</a>, <a
     href="https://ddspvocoder.github.io/ismir-demo/">demo</a>, <a
     href="https://github.com/YatingMusic/ddsp-singing-vocoders">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chien-Feng Liao, Jen-Yu Liu, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>KaraSinger: Score-free
     singing voice synthesis with VQ-VAE using Mel-spectrograms</b>,&quot; <br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2022 (<b><span style='color:brown'>ICASSP&#8217;22</span></b>).<br>
     (<a href="https://arxiv.org/abs/2110.04005">paper</a>, <a
     href="https://jerrygood0703.github.io/KaraSinger/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Bo-Yu Chen, Wei-Han Hsu,
     Wei-Hsiang Liao, Marco A. Mart&iacute;nez Ram&iacute;rez, Yuki Mitsufuji,
     and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Automatic DJ transitions with
     differentiable audio effects and generative adversarial networks</b>,&quot;
     <br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2022 (<b><span style='color:brown'>ICASSP&#8217;22</span></b>).<br>
     (<a href="https://arxiv.org/pdf/2110.06525.pdf">paper</a>, <a
     href="https://paulyuchen.com/djtransgan-icassp2022/">demo</a>, <a
     href="https://github.com/ChenPaulYu/DJtransGAN">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yi-Jen Shih, Shih-Lun Wu, Frank
     Zalkow, Meinard M&uuml;ller, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Theme Transformer: Symbolic
     music generation with theme-conditioned Transformer</b>,&quot;<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Multimedia
     (<b><span style='color:brown'>TMM</span></b>),<br>
     vol. 25, pp. 3495-3508, March 2022.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://arxiv.org/abs/2111.04093">paper</a>, <a
     href="https://github.com/atosystem/ThemeTransformer">code</a>, <a
     href="https://atosystem.github.io/ThemeTransformer/">demo</a>, <a
     href="https://www.youtube.com/watch?v=U2T_1HH0yH0">video</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Chih-Pin
     Tan, Chin-Jui Chang, Alvin W. Y. Su, and Yi-Hsuan Yang,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Music
     score expansion with variable-length infilling</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2021 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>21-LBD</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),<br>
     (<a href="https://archives.ismir.net/ismir2021/latebreaking/000019.pdf">paper</a>,
     <a href="https://tanchihpin0517.github.io/variable-length-piano-expansion/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Joann
     Ching and Yi-Hsuan Yang</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Learning
     to generate piano music with sustain pedals</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2021 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>21-LBD</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),<br>
     (<a href="https://arxiv.org/abs/2111.01216">paper</a>, <a
     href="https://github.com/joann8512/SusPedal-Gen">code</a>, <a
     href="https://joann8512.github.io/SusPedal-Gen/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Fu-Rong Yang, Yin-Ping Cho, Da-Yi
     Wu, Yi-Hsuan Yang, Shan-Hung Wu, and Yi-Wen Liu, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Mandarin singing voice
     synthesis with a phonology-based duration model</b>,&quot; <br>
     in Proc. Asia Pacific Signal and Information Processing Association Annual
     Summit and Conf. 2021 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>APSIPA ASC&#8217;21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://ieeexplore.ieee.org/document/9689619">paper</a>, code,
     demo)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chin-Jui Chang, Chun-Yi Lee, and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Variable-length music score
     infilling via XLNet and musically specialized positional encoding</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2021 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2108.05064.pdf">paper</a>, <a
     href="https://github.com/reichang182/variable-length-piano-infilling">code</a>,
     <a href="https://jackyhsiung.github.io/piano-infilling-demo/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Tun-Min Hung, Bo-Yu Chen,
     Yen-Tung Yeh, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>A benchmarking initiative for
     audio-domain music generation using the FreeSound Loop Dataset</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2021 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2108.01576.pdf">paper</a>, <a
     href="https://github.com/allenhung1025/LoopTest">code</a>, <a
     href="https://loopgen.github.io/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hsiao-Tzu Hung, Joann Ching,
     Seungheon Doh, Nabin Kim, Juhan Nam and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>EMOPIA: A multi-modal pop
     piano dataset for emotion recognition and emotion-based music generation</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2021 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2108.01374.pdf">paper</a>, <a
     href="https://github.com/annahung31/EMOPIA">code</a>, <a
     href="https://github.com/Dohppak/EMOPIA_cls">code2</a>, <a
     href="https://zenodo.org/record/5090631">database</a>, <a
     href="https://annahung31.github.io/EMOPIA/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Pedro Sarmento, Adarsh Kumar, C.
     J. Carr, Zack Zukowski, Mathieu Barthet, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>DadaGP: A dataset of
     tokenized GuitarPro songs for sequence models</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2021 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/pdf/2107.14653.pdf">paper</a>, <a
     href="https://github.com/dada-bots/dadaGP">code</a>, <a
     href="https://github.com/dada-bots/dadaGP">database</a>, <a
     href="https://drive.google.com/drive/folders/1USNH8olG9uy6vodslM3iXInBT725zult">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Antoine Liutkus, Ond&#345;ej
     C&iacute;fka, Shih-Lun Wu, Umut Simsekli, Yi-Hsuan Yang, and Gael Richard,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Relative positional encoding
     for Transformers with linear complexity</b>,&quot;<br>
     in Proc. Int. Conf. Machine Learning, long-presentation paper (<b><span
     style='color:brown'>ICML</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>&#8217;</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>21</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>acceptance
     rate: 9%), 2021.<br>
     (<a href="https://arxiv.org/abs/2105.08399">paper</a>, <a
     href="https://cifkao.github.io/spe/">demo</a>, <a
     href="https://github.com/aliutkus/spe">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Wen-Yi Hsiao, Jen-Yu Liu,
     Yin-Cheng Yeh, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Compound Word Transformer:
     Learning to compose full-song music over dynamic directed hypergraphs</b>,&quot;
     <br>
     in Proc. AAAI Conf. Artificial Intelligence (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>AAAI&#8217;</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>21</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>acceptance
     rate: 21%), 2021.<br>
     (<a href="https://arxiv.org/abs/2101.02402">paper</a>, <a
     href="https://ailabs.tw/human-interaction/compound-word-transformer-generate-pop-piano-music-of-full-song-length/">demo</a>,
     <a href="https://github.com/YatingMusic/compound-word-transformer">code</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/pub/hsiao21aaai-poster.pdf">poster</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yin-Cheng
     Yeh, Wen-Yi Hsiao, Satoru Fukayama, Tetsuro Kitahara, Benjamin Genchel,
     Hao-Min Liu, Hao-Wen Dong, Yian Chen, Terence Leong, and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Automatic melody harmonization with triad chords: A comparative
     study</b>,&quot; </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Journal of New Music Research (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>JNMR</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,<br>
     vol. 50, no. 1, pp. 37-51, Feb 2021.<br>
     (<a href="https://arxiv.org/abs/2001.02360">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Yu-Siang Huang,
     Wen-Yi Hsiao, and Yi-Hsuan Yang,<br>
     <b style='mso-bidi-font-weight:normal'>&quot;Automatic composition of
     guitar tabs by Transformers and groove modeling</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2020 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>20</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2008.01431">paper</a>, <a
     href="https://ss12f32v.github.io/Guitar-Transformer-Demo/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Shih-Lun Wu and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>The Jazz Transformer on the
     front line: Exploring the shortcomings of AI-composed music through
     quantitative measures</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2020 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>20</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2008.01307">paper</a>, <a
     href="https://drive.google.com/drive/folders/1-09SoxumYPdYetsUWHIHSugK99E2tNYD">demo</a>,
     <a href="https://github.com/slSeanWU/jazz_transformer">code1</a>, <a
     href="https://github.com/slSeanWU/MusDr">code2</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Bo-Yu Chen, Jordan Smith, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Neural loop combiner: Neural
     network models for assessing the compatibility of loops</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2020 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>20</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2008.02011">paper</a>, <a
     href="https://paulyuchen.com/Neural-Loop-Combiner-Demo/">demo</a>, <a
     href="https://github.com/mir-aidj/neural-loop-combiner">code</a>, data)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Antonio Ramires, Frederic Font,
     Dmitry Bogdanov, Jordan Smith, Yi-Hsuan Yang, Joann Ching, Bo-Yu Chen,
     Yueh-Kao Wu, Hsu Wei-Han, and Xavier Serra, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>The Freesound Loop Dataset
     and annotation tool</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2020 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>20</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2008.11507">paper</a>, <a
     href="https://github.com/aframires/freesound-loop-annotator">code</a>, <a
     href="https://zenodo.org/record/3967852">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Jen-Yu
     Liu, Yu-Hua Chen, Yin-Cheng Yeh and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Unconditional
     audio generation with generative adversarial networks and cycle
     regularization</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>&quot;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. INTERSPEECH 2020</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (<b><span
     style='color:brown'>INTERSPEECH</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>&#8217;20</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>).</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://arxiv.org/abs/2005.08526">paper</a>, <a
     href="https://github.com/ciaua/unagan">code</a>)</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Da-Yi
     Wu and Yi-Hsuan Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Speech-to-singing
     conversion based on boundary equilibrium GAN</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. INTERSPEECH 2020</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (<b><span
     style='color:brown'>INTERSPEECH</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>&#8217;20</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2005.13835">paper</a>, <a
     href="https://github.com/ericwudayi/speech2singing">code</a>, <a
     href="https://ericwudayi.github.io/Speech2Singing-DEMO">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Siang
     Huang</span><span lang=EN-US style='font-family:"Verdana",sans-serif'> and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Pop Music Transformer:
     Beat-based modeling and generation of expressive Pop piano compositions</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. ACM Multimedia (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MM&#8217;20</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2002.00212">paper</a>, <a
     href="https://github.com/YatingMusic/remi/">demo</a>, <a
     href="https://github.com/YatingMusic/remi/">code</a>).<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jayneel Parekh, Preeti Rao, and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Speech-to-singing conversion
     in an encoder-decoder framework</b>,&quot;<br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2020 (<b><span style='color:brown'>ICASSP&#8217;20</span></b>)<br>
     (<a href="https://arxiv.org/abs/2002.06595">paper</a>, <a
     href="https://jayneelparekh.github.io/icassp20/">demo</a>, <a
     href="https://github.com/jayneelparekh/sp2si-code">code</a>).<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Jen-Yu
     Liu, Yu-Hua Chen, Yin-Cheng Yeh, and Yi-Hsuan Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Score
     and lyrics-free singing voice generation</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. Int. Conf. Computational Creativity (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICCC&#8217;20</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/1912.11747">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Wen-Yi
     Hsiao, Yin-Cheng Yeh, Yu-Siang Huang, Chung-Yang Wang, Jen-Yu Liu,
     Tsu-Kuang Hsieh, Hsiao-Tzu Hung, Jun-Yuan Wang, and Yi-Hsuan Yang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Jamming
     with Yating: Interactive demonstration of a music composition AI</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2019 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>9-LBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>),<br>
     (<a href="http://archives.ismir.net/ismir2019/latebreaking/000003.pdf">paper</a>,
     <a href="https://www.youtube.com/watch?v=9ZIJrr6lmHg">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yin-Cheng
     Yeh, Jen-Yu Liu, Wen-Yi Hsiao, Yu-Siang Huang, and Yi-Hsuan Yang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Learning
     to generate Jazz and Pop piano music from audio via MIR techniques</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2019 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>9-LBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>),<br>
     (<a href="http://archives.ismir.net/ismir2019/latebreaking/000005.pdf">paper</a>,
     <a href="https://soundcloud.com/yating_ai/sets/ismir-2019-submission/">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Hsiao-Tzu
     Hung, Chung-Yang Wang, Yi-Hsuan Yang, Hsin-Min Wang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Improving
     automatic Jazz melody generation by transfer learning techniques</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Asia Pacific Signal
     and Information Processing Association Annual Summit and Conf. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>2019 </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>(</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:#C00000'>APSIPA ASC&#8217;19</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://arxiv.org/pdf/1908.09484.pdf">paper</a>, demo)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Frederic Tamagnan and Yi-Hsuan
     Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Drum fills detection and
     generation</b>,&quot; <br>
     in Proc. Int. Symp. Computer Music Multidisciplinary Research 2019 (<b><span
     style='color:#C00000'>CMMR</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:#C00000'>&#8217;1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:#C00000'>9</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (paper, <a href="https://frederictamagnan.github.io/drumfills/">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yun-Ning Hung, I-Tung Chiang,
     Yi-An Chen, and Yi-Hsuan Yang<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Musical composition style
     transfer via disentangled timbre representations</b>,&quot; <br>
     in Proc. Int. Joint Conf. Artificial Intelligence 2019 (<b><span
     style='color:brown'>IJCAI&#8217;19</span></b>;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>acceptance
     rate: 17.9%),<br>
     (<a href="https://arxiv.org/abs/1905.13567">paper</a>, <a
     href="https://biboamy.github.io/disentangle_demo/">demo</a>, <a
     href="https://github.com/biboamy/instrument-disentangle">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Bryan Wang and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Demonstration of
     PerformanceNet: A convolutional neural network model for score-to-audio
     music generation</b>,&quot; <br>
     in Proc. Int. Joint Conf. Artificial Intelligence 2019 (<b><span
     style='color:brown'>IJCAI&#8217;19</span></b>), demo paper,<br>
     (<a href="https://arxiv.org/pdf/1905.11689.pdf">paper</a>, <a
     href="https://github.com/bwang514/PerformanceNet">demo</a>, <a
     href="https://github.com/bwang514/PerformanceNet">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Towards a deeper
     understanding of adversarial losses</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1901.08753</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>January
     2019.<br>
     (<a href="https://arxiv.org/abs/1901.08753">paper</a>, <a
     href="https://github.com/salu133445/dan">code</a>)</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Vibert
     Thio, Hao-Min Liu, Yin-Cheng Yeh, and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>A
     minimal template for interactive web-based demonstrations of musical
     machine learning</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>&quot;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Workshop on
     Intelligent Music Interfaces for Listening and Creation 2019</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>MILC&#8217;19</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>)<br>
     (<a href="https://arxiv.org/abs/1902.03722">paper</a>, <a
     href="https://github.com/vibertthio/musical-ml-web-demo-minimal-template">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Bryan Wang and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>PerformanceNet:
     Score-to-audio music generation with multi-band convolutional residual
     network</b>,&quot; <br>
     in Proc. AAAI Conf. Artificial Intelligence (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>AAAI&#8217;1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>9</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>acceptance
     rate: 16.2%), 2019.<br>
     (<a href="https://arxiv.org/abs/1811.04357">paper</a>, <a
     href="https://github.com/bwang514/PerformanceNet">demo</a>, <a
     href="https://github.com/bwang514/PerformanceNet">code</a>, bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Min Liu and Yi-Hsuan Yang,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Lead
     sheet generation and arrangement by conditional generative adversarial
     network</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>,&quot;<br>
     in Proc. IEEE Int. Conf. Machine Learning and Applications (<b><span
     style='color:brown'>ICMLA&#8217;18</span></b>).<br>
     (<a href="https://arxiv.org/abs/1807.11161">paper</a>, <a
     href="https://liuhaumin.github.io/LeadsheetArrangement/">demo</a>, <a
     href="https://github.com/liuhaumin/LeadsheetArrangement">code</a>, <a
     href="https://github.com/liuhaumin/LeadsheetGAN">code2</a>, <a
     href="https://github.com/liuhaumin/LeadsheetVAE">code3</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Min Liu, Meng-Hsuan Wu and
     Yi-Hsuan Yang,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Lead
     sheet generation and arrangement via a hybrid generative model</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,&quot;<br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2018 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>8-LBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a
     href="https://drive.google.com/file/d/10uGRGEI9IOfu_LyzDSG393fGhwUrEOi4/view">paper</a>,
     <a href="https://github.com/liuhaumin/LeadsheetVAE">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong, Wen-Yi Hsiao and
     Yi-Hsuan Yang,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Pypianoroll:
     Open source Python package for handling multitrack pianorolls</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,&quot;<br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2018 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>8-LBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a
     href="https://drive.google.com/file/d/1pJ6v4CaA5__vq3JkpHUZTjxGxrHlfX0e/view">paper</a>,
     <a href="https://github.com/salu133445/pypianoroll">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Training generative
     adversarial networks with binary neurons by end-to-end backpropagation</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1810.04714</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>October
     2018.<br>
     (<a href="https://arxiv.org/pdf/1810.04714.pdf">paper</a>, <a
     href="https://github.com/salu133445/binarygan">code</a>, <a
     href="https://techxplore.com/news/2018-10-binarygan-adversarial-network-binary-neurons.html">press</a>)
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Cheng-Wei
     Wu, Jen-Yu Liu, Yi-Hsuan Yang, Jyh-Shing R. Jang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Singing style transfer using
     cycle-consistent boundary equilibrium generative adversarial networks</b>,&quot;<br>
     in </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Proc. Joint Workshop on Machine
     Learning for Music, extended abstract, 2018</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.<br>
     (<a href="https://arxiv.org/pdf/1807.02254.pdf">paper</a>, <a
     href="http://mirlab.org/users/haley.wu/cybegan/">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Convolutional generative
     adversarial networks with binary neurons for polyphonic music generation</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2018 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'1</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>8</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://archives.ismir.net/ismir2018/paper/000218.pdf">paper</a>,
     <a href="https://salu133445.github.io/bmusegan/">demo</a>, <a
     href="https://salu133445.github.io/bmusegan/">code</a>, <a
     href="https://salu133445.github.io/bmusegan/pdf/bmusegan-tmacw2018-slides.pdf">slides</a>,
     <a href="https://arxiv.org/abs/1804.09399">arxiv,</a> bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong, Wen-Yi Hsiao,
     Li-Chia Yang, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>MuseGAN: Multi-track
     sequential generative adversarial networks for symbolic music generation
     and accompaniment</b>,&quot; <br>
     in Proc. AAAI Conf. Artificial Intelligence (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>AAAI&#8217;18</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>2018.<br>
     (<a href="https://arxiv.org/abs/1709.06298">paper</a>, <a
     href="https://salu133445.github.io/musegan/">demo</a>, <a
     href="https://github.com/salu133445/musegan">code</a>, <a
     href="https://salu133445.github.io/musegan/dataset">data</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/dong18aaai.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hao-Wen Dong, Wen-Yi Hsiao,
     Li-Chia Yang, and Yi-Hsuan Yang,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>MuseGAN: Demonstration of a convolutional GAN based model for
     generating multi-track piano-rolls</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed
     two-page extended abstract) 2017 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>7-LBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>). <br>
     (<a
     href="https://hermandong.com/musegan/pdf/musegan-ismir2017-lbd-paper.pdf">paper</a>,
     <a href="https://salu133445.github.io/musegan/">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Li-Chia Yang, Szu-Yu Chou, and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>MidiNet: A convolutional
     generative adversarial network for symbolic-domain music generation</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int. Society
     for Music Information Retrieval</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'> Conf. 2017 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>7</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>), pp. 324-331.<br>
     (<a href="https://arxiv.org/abs/1703.10847">paper</a>, <a
     href="https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html">demo</a>,
     <a href="https://github.com/RichardYang40148/MidiNet">code</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang17ismir.txt">bib</a>) </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Shih-Yang
     Su, Cheng-Kai Chiu, Li Su, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>and </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Yi-Hsuan Yang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> <br>
     &quot;<b>Automatic conversion of pop music into chiptunes for 8-bit pixel
     art</b>,&quot; <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>in Proc.
     IEEE Int. Conf. Acoustics, Speech and Signal Processing 2017 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), accepted.<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/su17icassp_8bit.pdf">paper</a>,
     bib) [<a href="https://lemonatsu.github.io/">project webpage</a> (+demo
     +code)]</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
</ul>

<h3><a name=emotion><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:emotion'><span lang=EN-US style='font-size:14.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Music
and Emotion </span></span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><span
style='mso-spacerun:yes'>&nbsp;</span></span><span lang=EN-US style='font-size:
11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'>(back to <a
href="#top">top</a>)</span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Juan
     Sebasti&aacute;n Gomez-Ca&ntilde;&oacute;n, Estefan&iacute;a Cano, Tuomas
     Eerola, Perfecto Herrera, Xiao Hu, Yi-Hsuan Yang, and Emilia G&oacute;mez,
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Music Emotion Recognition: Towards new robust standards in
     personalized and context-sensitive applications</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Magazine
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>SPM</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>),</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> vol. 38, no. 6, pp. 106-114,
     Nov. 2021.<br>
     (<a href="https://ieeexplore.ieee.org/document/9591555">paper</a>, <a
     href="https://github.com/juansgomez87/datasets_emotion">repo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Eva
     Zangerle, Chih-Ming Chen, Ming-Feng Tsai and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Leveraging affective hashtags for ranking music recommendations</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Affective
     Computing (<b><span style='color:brown'>TAC</span></b>), </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 12, no. 1, pp. 78-91, 2021</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/8382228">paper</a>, bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Juan
     G&oacute;mez-Ca&ntilde;&oacute;n, Estefania Cano, Yi-Hsuan Yang, Perfecto
     Herrera, and Emilia Gomez,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Let's agree to disagree:
     Consensus entropy active learning for personalized music emotion
     recognition</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int. Society
     for Music Information Retrieval</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'> Conf. 2021 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ISMIR'</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>21</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://archives.ismir.net/ismir2021/paper/000029.pdf">paper</a>,
     code)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jianyu Fan, Yi-Hsuan Yang, Kui
     Dong, and Philippe Pasquier,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>A comparative study of
     Western and Chinese classical music based on soundscape models</b>,&quot;<br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2020 (<b><span style='color:brown'>ICASSP&#8217;20</span></b>)<br>
     (<a href="https://arxiv.org/abs/2002.09021">paper</a>, <a
     href="http://metacreation.net/ccmed_wcmed_soundscape/">data</a>).<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Hsiao-Tzu Hung, Yu-Hua Chen,
     Maximilian Mayerl, Michael V&ouml;tter, Eva Zangerle, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>MediaEval 2019 emotion and
     theme recognition task: A VQ-VAE based approach</b>,&quot; <br>
     MediaEval working note paper 2019 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MediaEval</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>&#8217;19</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a
     href="https://evazangerle.at/publication/mediaeval-19-tai/mediaeval-19-tai.pdf">paper</a>,
     <a href="https://github.com/annahung31/moodtheme-tagging">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Maximilian Mayerl, Michael
     V&ouml;tter, Hsiao-Tzu Hung, Bo-Yu Chen, Yi-Hsuan Yang, and Eva Zangerle, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Recognizing song mood and
     theme using convolutional recurrent neural networks</b>,&quot; <br>
     MediaEval working note paper 2019 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MediaEval</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>&#8217;19</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a
     href="https://evazangerle.at/publication/mediaeval-19-inn/mediaeval-19-inn.pdf">paper</a>,
     <a href="https://github.com/dbis-uibk/MediaEval2019">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Y.-H. Chin, J.-C. Wang, J.-C.
     Wang</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> and Y.-H. Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Predicting the probability density function of music emotion using
     emotion space mapping</b>,&quot; </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Transactions on Affective
     Computing</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>TAC</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>), </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 9, no. 4, pp. 541-549, Oct.-Dec. 2018.<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/chin18tac.pdf">paper</a>,
     bib)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yi-Wei Chen, Yi-Hsuan Yang, and
     Homer H. Chen,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Cross-cultural music emotion
     recognition by adversarial discriminative domain adaptation</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Machine Learning and Applications (<b><span
     style='color:brown'>ICMLA&#8217;18</span></b>).<br>
     (<a href="https://ieeexplore.ieee.org/document/8614101">paper</a>, <a
     href="https://github.com/YiWeiWayne/Cross-dataset-mood-prediction">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>X. Hu</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and Y.-H. Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>The mood of Chinese pop music: Representation and recognition</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Journal of the Association for
     Information Science and Technology (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>JAIST</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>), </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 68, no. 8, August 2017, DOI: 10.1002/asi.23813</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.23813/full">paper</a>,
     bib)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>X. Hu</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and Y.-H. Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Cross-dataset and cross-cultural music mood prediction: A case on
     Western and Chinese pop songs</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Transactions on Affective
     Computing</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>TAC</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>), </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 8, no. 2, pp. 228-240, Apr. 2017</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/7395312">paper</a>, bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Y.-A. Chen, J.-C. Wang, Y.-H.
     Yang, H.-H. Chen, <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Component tying for mixture model adaptation in
     personalization of music emotion recognition</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> <br>
     IEEE/ACM Transactions on Audio, Speech, and Language Processing (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>TASLP</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>),<span
     style='mso-spacerun:yes'>&nbsp; </span><br>
     vol. 25, no. 7, pp. 1409-1420, Jul. 2017. </span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:green'>(</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:green'>a figure of this paper was selected as the cover of this
     issue</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:green'>)</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/7898399">paper</a>, bib)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>A. Aljanaki, Y.-H. Yang, and M.
     Soleymani, <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Developing a benchmark for emotional analysis of
     music</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     <br>
     </span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>PLOS ONE</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <br>
     vol, 12, no. 3, e0173392.doi:10.1371/journal.pone.0173392, Mar. 2017.<br>
     (<a
     href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0173392">paper</a>,
     <a
     href="http://journals.plos.org/plosone/article/citation?id=10.1371/journal.pone.0173392">bib</a>)<o:p></o:p></span></li>
</ul>

<p class=MsoListParagraph style='margin-top:0cm;margin-right:0cm;margin-bottom:
12.0pt;margin-left:36.0pt;mso-para-margin-top:0cm;mso-para-margin-right:0cm;
mso-para-margin-bottom:12.0pt;mso-para-margin-left:0gd;text-indent:-18.0pt;
mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;
mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol'><span
style='mso-list:Ignore'>&middot;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US style='font-family:"Verdana",sans-serif'>Yuan-Pin
Lin, Ping-Keng Jao, and Yi-Hsuan Yang, <br>
</span><span lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'>&quot;</span><b style='mso-bidi-font-weight:normal'><span
lang=EN-US style='font-family:"Verdana",sans-serif'>Improving cross-day
EEG-based emotion classification using robust principal component analysis</span></b><span
lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span lang=EN-US
style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;</span><span
lang=EN-US style='font-family:"Verdana",sans-serif'> <br>
Frontiers in Computational Neuroscience (</span><b><span lang=EN-US
style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
color:brown'>FCN</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),
<br>
2017.<br>
(<a href="https://www.ncbi.nlm.nih.gov/pubmed/28769778">paper</a>, bib)</span></p>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>J.-C. Wang, Y.-H. Yang and H.-M. Wang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><br>
     &quot;<b>Affective music information retrieval</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in Emotions and Personality in Personalized Services, M. Tkal&#269;i&#269;
     et al, editors,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><br>
     Springer International Publishing</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>, 2016</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="http://www.springer.com/in/book/9783319314112">link</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang, J.-C. Wang, Y.-A. Chen, and H. H.
     Chen</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, <br>
     &quot;<b>Model Adaptation for Personalized Music Emotion Recognition</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in Handbook of Pattern Recognition and Computer Vision, C.-H. Chen,
     editor,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><br>
     World Scientific Publishing</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>, Feb. 2016</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="http://www.worldscientific.com/worldscibooks/10.1142/9503">link</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-H.
     Yang and Y.-C. Teng,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Quantitative study of music listening behavior in a smartphone
     context</b>,&quot;</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>ACM Transactions on Interactive
     Intelligent Systems (<b><span style='color:brown'>TiiS</span></b>),</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>vol. 5, no. 3, article 14, Aug.
     2015.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://dl.acm.org/doi/10.1145/2738220">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang15tiis.txt">bib</a>,
     online <a
     href="http://mac.citi.sinica.edu.tw/~yang/pub/yang15tiis_appendix.pdf">appendix</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>M.
     Soleymani, Y.-H. Yang, G. Irie, and A. Hanjalic, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Challenges and Perspectives for Affective Analysis in Multimedia</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Affective
     Computing (<b><span style='color:brown'>TAC</span></b>), </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 6, no. 3, pp. 206-208, Jul.-Sept., 2015<br>
     (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7235006">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/soleymani15tac.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-C.
     Wang, Y.-H. Yang, H.-M. Wang, and S.-K. Jeng,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Modeling the affective
     content of music with a Gaussian mixture model</b>,&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Affective
     Computing (<b><span style='color:brown'>TAC</span></b>),</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>vol. 6, no. 1, pp. 56-68</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, Feb 2015</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://homepage.iis.sinica.edu.tw/papers/whm/18116-F.pdf">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/wang15tac.txt">bib</a>, <a
     href="http://slam.iis.sinica.edu.tw/demo/aeg/">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>P.-K.
     Jao, Y.-P. Lin, Y.-H. Yang, and T.-P. Jung, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Using robust principal component analysis to alleviate day-to-day
     variability in EEG based emotion classification</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Annual Int. Conf. IEEE
     Engineering in Medicine and Biology Society </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>2015 </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>(<b><span
     style='color:#C00000'>EMBC&#8217;15</span></b>), pp. 570-573. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><a
     href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7318426"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span class=MsoHyperlink><span lang=EN-US
     style='color:windowtext;text-decoration:none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>A. Aljanaki, Y.-H. Yang, and M.
     Soleymani,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Musical emotion variation
     detection from acoustic content - lessons learned from developing
     MediaEval &quot;Emotion in Music&quot; benchmark</b>,&quot; <br>
     in Proc. Int. Conf. Music and Emotion 2015 (<b><span style='color:brown'>ICME4</span></b>).<br>
     (<a
     href="http://www.cs.uu.nl/groups/MG/multimedia/publications/art/ICME4-emotion.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>J.-W. Peng, S.-W. Sun, W.-H.
     Cheng, and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>eMosic: Mobile media pushing
     through social emotion sensing</b>,&quot;<br>
     in Proc. ACM Multimedia 2015 (<b><span style='color:brown'>MM&#8217;15</span></b>),
     demo paper.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Y.-A. Chen, Y.-H. Yang, J.-C.
     Wang and H.-H. Chen,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>The AMG1608 dataset for music
     emotion recognition</b>,&quot;<br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;15</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 693-697.<br>
     (<a href="https://ieeexplore.ieee.org/document/7178058">paper</a>, <a
     href="http://mpac.ee.ntu.edu.tw/dataset/AMG1608/">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>M. Soleymani, A. Aljanaki, Y.-H.
     Yang, M. N. Caro, F. Eyben, K. Markov, B. Schuller, R. Veltkamp, F.
     Weninger, and F. Wiering,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Emotional analysis of music:
     A comparison of methods</b>,&quot; <br>
     in Proc. ACM Multimedia, short paper (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MM</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>&#8217;14</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),
     pp. 1161-1164.<br>
     (<a href="https://dl.acm.org/doi/10.1145/2647868.2655019">paper</a>, <a
     href="http://cvml.unige.ch/databases/emoMusic/">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>A. Aljanaki, Y.-H. Yang, and M.
     Soleymani,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Emotion in Music Task at MediaEval 2014</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>MediaEval Workshop </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>(</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>MediaEval</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;14</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), extended abstract.<br>
     (<a href="http://ceur-ws.org/Vol-1263/mediaeval2014_submission_33.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>X. Hu and Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Cross-cultural mood regression
     for music digital libraries</b>,&quot;<br>
     in Proc. IEEE/ACM Joint Conf. Digital Libraries 2014 (<b><span
     style='color:brown'>DL&#8217;14</span></b>).<br>
     (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6970230">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>X. Hu and Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>A study on cross-cultural and
     cross-dataset generalizability of music mood regression models</b>,&quot;<br>
     in Proc. Sound and Music Computing Conf. 2014 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>SMC&#8217;14</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>), pp. 1149-1155.<br>
     (<a
     href="https://quod.lib.umich.edu/i/icmc/bbp2372.2014.176/1/--study-on-cross-cultural-and-cross-dataset-generalizability?page=root;size=150;view=text">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>J.-Y. Liu, S.-Y. Liu and Y.-H.
     Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>LJ2M Dataset: Toward better
     understanding of music listening behavior and user mood</b>,&quot; <br>
     IEEE Int. Conf. Multimedia and Expo. 2014 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ICME</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>&#8217;14</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://ieeexplore.ieee.org/document/6890172">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/LJ">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Y.-A. Chen, J.-C. Wang, Y.-H.
     Yang and H.-H. Chen,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Linear regression-based
     adaptation of music emotion recognition models for personalization</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;14</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 2149-2153.<br>
     (<a href="https://ieeexplore.ieee.org/document/6853979">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-P</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Lin, Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>and
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>T</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>-P</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Jung</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Fusion of Electroencephalogram dynamics and musical contents for
     estimating emotional responses in music listening</b></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Frontiers in Neuroscience, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 8, no. 94, pp. 1-14, May 2014.<br>
     (<a
     href="http://journal.frontiersin.org/Journal/10.3389/fnins.2014.00094/abstract">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/lin14fin.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> and</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>J</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.-</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>. L</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>iu</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, <br>
     &quot;<b>Quantitative study of music listening behavior in a social and
     affective context</b>,&quot; </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     Special Issue on </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Social Media as Sensors</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><br>
     IEEE Transactions on Multimedia (<b><span style='color:brown'>TMM</span></b>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 15, no. 6, pp. 1304-1315, Oct. 2013.<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(<a
     href="http://mac.citi.sinica.edu.tw/~yang/pub/yang13tmm.pdf">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/LJ/">data</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang13tmm.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>K.-S.
     Lin, A. Lee, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>,
     C.-T. Lee, and H.-H. Chen, <br>
     &quot;<b>Automatic highlights extraction for drama video using music
     emotion and human face features</b>,&quot; <br>
     Neurocomputing</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>NEUCOM</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Elsevier,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 119, pp. 111-117, Nov. 2013,</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.<br>
     (<a href="http://authors.elsevier.com/sd/article/S0925231212009071">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, bib</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>M. Soleymani, M. N. Caro, E.
     Schmidt, C.-Y. Sha, and Y.-H. Yang,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>The MediaEval 2013 brave new task: Emotion in Music</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>MediaEval Workshop </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>(</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>MediaEval</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;13</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>in
     conjunction with ACM Multimedia, extended abstract.<br>
     (<a href="http://ceur-ws.org/Vol-1043/mediaeval2013_submission_5.pdf">paper</a>,
     <a href="http://cvml.unige.ch/databases/emoMusic/">data</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>M. Soleymani, M. N. Caro, E.
     Schmidt, C.-Y. Sha, and Y.-H. Yang,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>1000
     songs for emotional analysis of music</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>Int. Workshop on
     Crowdsourcing for Multimedia</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'> 201</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>3</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>CrowdMM</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> in conjunction with ACM Multimedia (MM)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, pp. 1-6.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><br>
     (<a href="http://dl.acm.org/citation.cfm?id=2506365">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://cvml.unige.ch/databases/emoMusic/">data</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>Machine recognition of music emotion: A review</b>,&quot; <br>
     ACM Transactions on Intelligent Systems and Technology (<b><span
     style='color:brown'>TIST</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>vol. 3, no. 3, May 2012.<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/yang12tist.pdf">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang12tist.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-C.
     Wang, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, H.-M.
     Wang, and S.-K. Jeng,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Personalized music emotion recognition via model adaptation</b></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;<br>
     in Proc. Asia Pacific Signal and Information Processing Association Annual
     Summit and Conf</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> 2012 (</span><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>APSIPA ASC</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>'12</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>).<br>
     (<a href="http://www.iis.sinica.edu.tw/papers/asriver/2794-F.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-C.
     Wang, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, H.-M.
     Wang, and S.-K. Jeng,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>The Acoustic Emotion Gaussians model for emotion-based music
     annotation and retrieval</b></span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<br>
     in Proc. ACM Multimedia 2012 (<b><span style='color:brown'>MM'12</span></b>),
     <b><span style='color:green'>full paper</span></b></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> </span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:green'>(acceptance rate 21%)</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     pp. </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>89</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>98</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2393347.2393367">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/wang12mm.txt">bib</a>, <a
     href="http://slam.iis.sinica.edu.tw/demo/aeg/">code</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-C.
     Wang, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, K.-C.
     Chang, H.-M. Wang, and S.-K. Jeng, <br>
     &quot;<b>Exploring the relationship between categorical and dimensional
     emotion semantics of music</b>,&quot; <br>
     in Int. Workshop on Music Information Retrieval with User-Centered and
     Multimodal Strategies (<b><span style='color:brown'>MIRUM'12</span></b>),
     in conjunction with ACM Multimedia (MM), pp. </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>63</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>-</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>68</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2390848.2390865">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and X. Hu, <br>
     &quot;<b>Cross-cultural music mood classification: A comparison of English
     and Chinese songs</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval 2012 (<b><span
     style='color:brown'>ISMIR'12</span></b>), pp. 1</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>9</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>-</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>24</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="https://archives.ismir.net/ismir2012/paper/000019.pdf">paper</a>)
     <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-C.
     Lin, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span> and H.-H.
     Chen, <br>
     &quot;<b>Exploiting online tags for music emotion classification</b>,&quot;
     <br>
     Special Issue on Social Media, <br>
     ACM Transactions on Multimedia Computing, Communications, and Applications
     (<b><span style='color:brown'>TOMCCAP</span></b>), </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>vol. 7S, no. 1, Oct. 2011.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2037683">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, bib</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>Prediction of the distribution of perceived music emotions using
     discrete samples</b>,&quot; <br>
     IEEE Transactions on Audio, Speech and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), <br>
     vol. 19, no. 7, pp. 2184-2196, Sept. 2011.<br>
     (<a href="https://ieeexplore.ieee.org/document/5719548">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang11taslpB.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) [<a href="MER/NTUMIR-60">project page</a>] <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>Ranking-based emotion recognition for music organization and
     retrieval</b>,&quot; <br>
     IEEE Transactions on Audio, Speech and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), <br>
     vol. 19, no. 4, pp. 762-774, May 2011.<br>
     (<a href="https://ieeexplore.ieee.org/document/5545401">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang11taslpA.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) [<a href="MER/NTUMIR-1240">project page</a>] <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     <b>Music Emotion Recognition</b>, <br>
     CRC Taylor &amp; Francis Books, Feb. 2011 <br>
     (<a href="http://www.crcpress.com/product/isbn/9781439850466">link</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang11book.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>Searching music in the emotion plane</b>,&quot; <br>
     IEEE MMTC E-Letter, November issue, 2009, invited paper.<br>
     (paper) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, and H.-H. Chen, <br>
     &quot;<b>Personalized music emotion recognition</b>,&quot; <br>
     in Proc. ACM Int. Conf. Information Retrieval 2009 (<b><span
     style='color:brown'>SIGIR'09</span></b>), Boston, USA, short paper, pp.
     748-749. <br>
     (<a href="http://dl.acm.org/citation.cfm?id=1572109">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>Music emotion ranking</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing 2009 (<b><span
     style='color:brown'>ICASSP'09</span></b>), Taipei, Taiwan, pp. 1657-1660. <br>
     (<a
     href="http://ieeexplore.ieee.org/document/4959919/?reload=true&amp;arnumber=4959919">paper</a>)
     [project page, include dataset] <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-C.
     Lin, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, H.-H.
     Chen, I-Bin Liao, and Yeh-Chin Ho <br>
     &quot;<b>Exploiting genre for music emotion classification</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2009 (<b><span
     style='color:brown'>ICME'09</span></b>), New York, USA, pp. 618-621.<br>
     (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5202572">paper</a>)
     [<a href="http://mpac.ee.ntu.edu.tw/~vagante/genreEmo">project page</a>,
     include dataset] <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, H.-T. Cheng, and H.-H. Chen, <br>
     &quot;<b>Mr.Emo: Music retrieval in the emotion plane</b>,&quot; <br>
     in Proc. ACM Multimedia 2008 (<b><span style='color:brown'>MM'08</span></b>)
     (demonstration), pp. 1003-1004. <br>
     (<a href="http://dl.acm.org/citation.cfm?id=1459550">paper</a>, <a
     href="http://www.youtube.com/watch?v=ra55xO20UHU">demo</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>T.-L.
     Wu et al, <br>
     &quot;<b>Interactive content presenter based on expressed emotion and
     physiological feedback</b>,&quot; <br>
     in Proc. ACM Multimedia 2008 (<b><span style='color:brown'>MM'08</span></b>)
     (demonstration), pp. 1009-1010. <br>
     (<a href="http://dl.acm.org/citation.cfm?id=1459554">paper</a>, demo) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, H.-T. Cheng, I.-B. Liao, Yeh-Chin Ho, and H.-H. Chen, <br>
     &quot;<b>Toward multi-modal music emotion classification</b>,&quot; <br>
     in Proc. Pacific-Rim Conf. Multimedia 2008 (<b><span style='color:brown'>PCM'08</span></b>),
     pp. 70-79. <br>
     (<a href="https://users.ece.cmu.edu/~hengtzec/papers/pcm08_multimodal.pdf">paper</a>,
     <a href="pub/PCM08.ppt.pdf">slides</a>) <o:p></o:p></span></li>
</ul>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l3 level1 lfo4;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-F. Su, Y.-C. Lin, and H.-H. Chen, <br>
     &quot;<b>Music emotion recognition: The role of individuality</b>,&quot; <br>
     in Proc. ACM SIGMM Int. Workshop on Human-centered Multimedia 2007, in conjunction
     with ACM Multimedia (<b><span style='color:brown'>ACM MM/HCM'07</span></b>),
     Augsburg, Germany, pp. 13-21. <br>
     (<a href="http://dl.acm.org/citation.cfm?id=1290132">paper</a>, <a
     href="hcm07/hcm07_yang.ppt">slides</a>) [<a href="MER/hcm07/index.html">project
     page</a>(include dataset and the software <span style='color:blue'>'AnnoEmo'</span>)]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l3 level1 lfo4;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, Y.-F. Su, and H.-H. Chen, <br>
     &quot;<b>A regression approach to music emotion recognition</b>,&quot; <br>
     IEEE Transactions on Audio, Speech and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), <br>
     vol. 16, no. 2, pp. 448-457, Feb. 2008.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> </span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:green'>(IEEE Signal Processing Society Young Author Best Paper
     Award)</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="https://ieeexplore.ieee.org/document/4432654">paper</a>, <a
     href="pub/taslp08.ppt.pdf">slides</a></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/yang08taslp.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) [<a href="MER/taslp08">project page</a>, include
     dataset] <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l3 level1 lfo4;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, Y.-F. Su, and H.-H. Chen, <br>
     &quot;<b>Music emotion classification: A regression approach</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2007 (<b><span
     style='color:brown'>ICME'07</span></b>), Bejing, China, pp. 208-211. <br>
     (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4284623">paper</a>,
     <a href="icme07/ICME07_poster.ppt">poster</a>) [<a
     href="MER/icme07/index.html">project page</a>(include dataset)]<o:p></o:p></span></li>
</ul>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l6 level1 lfo5;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     C.-C Liu, and H.-H. Chen, <br>
     &quot;<b>Music emotion classification: A fuzzy approach</b>,&quot; <br>
     in Proc. ACM Multimedia 2006 (<b><span style='color:brown'>ACM MM'06</span></b>),
     Santa Barbara, CA, USA, pp. 81-84. (short paper)(with travel grant) <br>
     (<a href="http://dl.acm.org/citation.cfm?id=1180665">paper</a>) [<a
     href="MER/mm06/index.html">project page</a>]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l6 level1 lfo5;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C.-C
     Liu, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, P.-H. Wu,
     and H.-H. Chen, <br>
     &quot;<b>Detecting and classifying emotion in popular music</b>,&quot; <br>
     in Proc. 9th Joint Int. Conf. Information Sciences / 7th Int. Conf.
     Computer Vision, Pattern Recognition and Image Processing 2006 (<b><span
     style='color:brown'>JCIS/CVPRIP'06</span></b>), Kaohsiung, Taiwan, pp.
     996-999. <br>
     (<a
     href="https://ai2-s2-pdfs.s3.amazonaws.com/4daf/e64e7aa4a5d5d09c0dca30bc6286f1260e1a.pdf">paper</a>)<o:p></o:p></span></li>
</ul>

<h3><a name=classification><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:classification'><span lang=EN-US
style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'>Music/sound Classification and Auto-tagging</span></span><span
lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'> </span><span lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
font-weight:normal;mso-bidi-font-weight:bold'>(back to <a href="#top">top</a>)</span><span
lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yi-Hui Chou, I-Chun Chen,
     Chin-Jui Chang, Joann Ching, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>MidiBERT-Piano: BERT-like
     Pre-training for Symbolic Piano Music Classification Tasks</b>,&quot; <br>
     Journal of Creative Music Systems (<b><span style='color:brown'>JCMS</span></b>),
     <br>
     vol. 8, no. 1, 2024.<br>
     (<a href="https://www.jcms.org.uk/article/id/1064/">paper</a>, <a
     href="https://github.com/wazenmai/MIDI-BERT">code</a>, <a
     href="https://zenodo.org/record/5089279#.YOz0SJgzbX4">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Wei-Han Hsu, Bo-Yu Chen, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Deep learning based EDM
     subgenre classification using Mel-spectrogram and tempogram features</b>,&quot;
     <br>
     in ArXiv e-prints, abs/2110.08862, October 2021.<br>
     (<a href="https://arxiv.org/pdf/2110.08862.pdf">paper</a>, <a
     href="https://github.com/mir-aidj/EDM-subgenre-classifier">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Joann Ching, Antonio Ramires, and<b
     style='mso-bidi-font-weight:normal'> Yi-Hsuan Yang, </b><br>
     &quot;<b style='mso-bidi-font-weight:normal'>Instrument role
     classification: Auto-tagging for loop based music</b>,&quot; <br>
     in Proc. Joint Conference on AI Music Creativity 2020<br>
     (<a
     href="https://boblsturm.github.io/aimusic2020/papers/CSMC__MuMe_2020_paper_35.pdf">paper</a>,
     <a href="https://zenodo.org/record/3967852">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Tsung-Han Hsieh, Kai-Hsiang
     Cheng, Zhe-Cheng Fan, Yu-Ching Yang, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Addressing the confounds of
     accompaniments in singer identification</b>,&quot;<br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2020 (<b><span style='color:brown'>ICASSP&#8217;20</span></b>)<br>
     (<a href="https://arxiv.org/abs/2002.06817">paper</a>, <a
     href="https://github.com/bill317996/Singer-identification-in-artist20">code</a>).<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Juhan
     Nam, Keunwoo Choi, Jongpil Lee, Szu-Yu Chou, and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Deep learning for audio-based music classification and tagging</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Magazine
     (<b><span style='color:brown'>SPM</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 36, no. 1, pp. 41-51, Jan 2019</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/8588424">paper</a>, bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Kai-Hsiang Cheng, Szu-Yu Chou,
     and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Multi-label few-shot learning
     for sound event recognition</b>,&quot; <br>
     in Proc. IEEE Int. Workshop on Multimedia Signal Processing 2019 (<b><span
     style='color:brown'>MMSP&#8217;19</span></b>), accepted.<br>
     (<a href="https://ieeexplore.ieee.org/document/8901732">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Eva Zangerle, Michael
     V&ouml;tter, Ramona Huber, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Hit song prediction:
     Leveraging low- and high-level audio features</b>,&quot; <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Int. Society for Music
     Information Retrieval 201</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>9</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (<b><span style='color:brown'>ISMIR'1</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>9</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     pp. 319-326.<br>
     (<a href="http://archives.ismir.net/ismir2019/paper/000037.pdf">paper</a>)
     [<a href="https://zenodo.org/record/3258042">project webpage</a>]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Szu-Yu Chou, Kai-Hsiang Cheng,
     Jyh-Shing Roger Jang, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Learning to match transient sound
     events using attentional similarity for few-shot sound recognition</b>,&quot;
     <br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2019 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;19</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 26-30.<br>
     (<a href="https://arxiv.org/abs/1812.01269">paper</a>, <a
     href="https://github.com/kevinco27/attentional-similarity">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Szu-Yu Chou, Jyh-Shing Roger
     Jang, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Learning to recognize
     transient sound events using attentional supervision</b>,&quot; <br>
     in Proc. Int. Joint Conf. Artificial Intelligence 2018 (<b><span
     style='color:brown'>IJCAI&#8217;18</span></b>), pp. 3336-3342.<br>
     (<a href="https://www.ijcai.org/proceedings/2018/0463.pdf">paper</a>, <a
     href="https://github.com/fearofchou/mmnet">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Lang-Chi Yu, Yi-Hsuan Yang,
     Yun-Ning Hung, Yi-An Chen,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Hit song prediction for pop
     music by Siamese CNN with ranking loss</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1710.10814</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Oct
     2017.<br>
     (<a href="https://arxiv.org/abs/1710.10814">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Szu-Yu Chou, Jyh-Shing Roger
     Jang, and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>FrameCNN: A weakly-supervised
     learning framework for frame-wise acoustic event detection and classification</b>,&quot;
     <br>
     in Proc. Detection and Classification of Acoustic Scenes and Events
     Workshop 2017 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>DCASE&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), extended abstract.<br>
     (<a
     href="http://www.cs.tut.fi/sgn/arg/dcase2017/documents/challenge_technical_reports/DCASE2017_Chou_102.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Li-Chia Yang, Szu-Yu Chou, Jen-Yu
     Liu, Yi-Hsuan Yang, and Yi-An Chen,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Revisiting the problem of
     audio-based hit song prediction using convolutional neural networks</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2017 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/1704.01280">paper</a>) [<a
     href="https://richardyang40148.github.io/TheBlog/post_hit.html">project
     webpage</a>]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Ting-Wei Su, Jen-Yu Liu, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Weakly-supervised audio event
     detection using event-specific Gaussian filters and fully convolutional
     networks</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2017 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://wessu.github.io/publications/icassp2017wsl-aed.pdf">paper</a>)
     [<a href="https://tweihaha.github.io/research/aed-by-cnn/">project webpage</a>]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>J.-Y. Liu, S.-K. Jeng, and Y.-H.
     Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Applying topological
     persistence in convolutional neural network for music audio signals</b>,&quot;
     <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1608.07373</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Aug
     2016.<br>
     (<a href="https://arxiv.org/abs/1608.07373">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>J.-Y. Liu and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Event localization in music
     auto-tagging</b>,&quot; <br>
     in Proc. ACM Multimedia 2016, (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MM</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>&#8217;16</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:green'>full paper</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, <b><span style='color:green'>accept</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:green'>ance</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:green'> rate=2</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:green'>0</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:green'>%</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>pp.
     1048-1057.<br>
     (<a href="https://dl.acm.org/doi/10.1145/2964284.2964292">paper</a>, <a
     href="https://github.com/ciaua/clip2frame">code</a>, <a
     href="http://clip2frame.ciaua.com/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>P.-K.
     Jao and Y.-H. Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Music annotation and retrieval using unlabeled exemplars:
     correlation and sparse code</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Letters
     (<b><span style='color:brown'>SPL</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 22, no. 10, pp. 1771-1775, Oct. 2015<br>
     (<a href="https://ieeexplore.ieee.org/abstract/document/7106493">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/jao15spl.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>L.
     Su, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>H.-M.
     Lin</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, and Y.-H. Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Sparse modeling of magnitude and phase-derived spectra for playing
     technique classification</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>/ACM</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Transactions on Audio, Speech and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 22, no. 12, pp. 2122-2132, Dec. 2014.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>(<a
     href="https://ieeexplore.ieee.org/document/6918444">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/su14taslp.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>L.
     Su, C.-C. M. Yeh, J.-Y. Liu, J.-C. Wang, and Y.-H. Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>A systematic evaluation of the bag-of-frames representation for
     music information retrieval</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     Special Issue on Music Data Mining,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Multimedia
     (<b><span style='color:brown'>TMM</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 16, no. 5, pp. 1188-1200, Aug. 2014.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="https://ieeexplore.ieee.org/document/6763025">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/su14tmm.txt">bib</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-C. M. Yeh, P.-K. Jao, and
     Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>AWtoolbox: Characterizing
     audio information using audio words</b>,&quot; <br>
     in Proc. ACM Multimedia 2014, short paper (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>MM</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>&#8217;14</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>),
     pp. 809-812.<br>
     (<a
     href="https://mcyeh.github.io/paper/2014_mm_awtoolbox_characterizing_audio.pdf">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/awtoolbox/">code</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>S.-Y. Wang, J.-C. Wang, Y.-H.
     Yang and H.-M. Wang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Towards time-varying music
     auto-tagging based on CAL500 Expansion</b>,&quot; <br>
     IEEE Int. Conf. Multimedia and Expo. 2014 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ICME</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>&#8217;14</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://homepage.iis.sinica.edu.tw/papers/whm/17069-F.pdf">paper</a>,
     <a href="http://slam.iis.sinica.edu.tw/demo/CAL500exp/">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>P.-K. Jao, C.-C. M. Yeh and Y.-H.
     Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Modified LASSO screening for
     audio word-based music classification using large-scale dictionary</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;14</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 5207-5211.<br>
     (<a href="https://ieeexplore.ieee.org/document/6854596">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><span
     style='mso-spacerun:yes'>&nbsp;</span>L.-F. Yu, L. Su and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Sparse cepstral codes and
     power scale for instrument identification</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;14</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 7460-7464.<br>
     (<a href="https://ieeexplore.ieee.org/document/6855050">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-C. M. Yeh, J.-C. Wang, Y.-H.
     Yang and H.-M. Wang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Improving music auto-tagging
     by intra-song instance bagging</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;14</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 2139-2143.<br>
     (<a href="https://ieeexplore.ieee.org/document/6853977">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>L. Su and </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Sparse modeling for artist identification: Exploiting phase
     information and vocal separation</b></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;<br>
     in Proc. Int. Society for Music Information Retrieval 201</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>3</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (<b><span style='color:brown'>ISMIR'1</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     pp. 349-354.</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="https://archives.ismir.net/ismir2013/paper/000054.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>P.-K. Jao, L. Su, and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Analyzing the dictionary
     properties and sparsity constraints for a dictionary-based music genre
     classification system</b>,&quot;<br>
     in Proc. Asia Pacific Signal and Information Processing Association Annual
     Summit and Conf. (<b><span style='color:brown'>APSIPA ASC&#8217;13</span></b>),
     2013.<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(<a
     href="https://ieeexplore.ieee.org/document/6694278">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-C. Yeh and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Towards a more efficient
     sparse coding based audio-word feature extraction system</b>,&quot;<br>
     in Proc. Asia Pacific Signal and Information Processing Association Annual
     Summit and Conf. (<b><span style='color:brown'>APSIPA ASC&#8217;13</span></b>),
     2013.<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(<a
     href="https://ieeexplore.ieee.org/document/6694252">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><span
     style='mso-spacerun:yes'>&nbsp;</span></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Towards real-time music auto-tagging using sparse features</b></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;<br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 201</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>3</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>ICME</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     oral (top 13%), </span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:green'>best paper
     candidate</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><br>
     (<a href="https://ieeexplore.ieee.org/document/6607505">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://mac.citi.sinica.edu.tw/Cal10k_mac">data</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-C</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yeh, L</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Su, and Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Dual-layer bag-of-frames model for music genre classification</b></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing 201</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>3</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>ICASSP</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>).<br>
     (<a href="https://mcyeh.github.io/paper/2013_icassp_dual_layer_bof.pdf">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Sha, Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Y.-C. Lin,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> and H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     H. Chen,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Singing voice timbre classification of Chinese popular music</b></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing 201</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>3</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>ICASSP</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>).<br>
     (<a href="https://ieeexplore.ieee.org/document/6637745">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-Y.
     Liu, C.-C. Yeh, Y.-C. Teng, and <span style='mso-bidi-font-weight:bold'>Y.-H.
     Yang</span>, <br>
     &quot;<b>Bilingual analysis of song lyrics and audio words</b>,&quot; <br>
     in Proc. ACM Multimedia 2012 (<b><span style='color:brown'>MM'12</span></b>),
     short paper, pp. </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>829</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>83</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>2.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2393347.2396323">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C.-C.
     Yeh and <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, <br>
     &quot;<b>Supervised dictionary learning for music genre classification</b>,&quot;
     <br>
     in Proc. ACM International Conference on Multimedia Retrieval 2012 (<b><span
     style='color:brown'>ICMR'12</span></b>)</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>, eight pages</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2324859">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     D. Bogdanov, P. Herrera, and M. Sordo, <br>
     &quot;<b>Music retagging using label propagation and robust principal
     component analysis</b>,&quot; <br>
     in Int. Workshop on Advances in Music Information Research (<b><span
     style='color:brown'>AdMIRe'12</span></b>), in conjunction with Int. World
     Wide Web Conference (WWW), pp. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>869</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>876</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2188217">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-H.
     Kuo, H.-T. Lin, W.-H. Cheng, <span style='mso-bidi-font-weight:bold'>Y.-H.
     Yang</span>, and W.-H. Hsu, <br>
     &quot;<b>Unsupervised auxiliary visual words discovery for large-scale
     image object retrieval</b>,&quot; <br>
     in Proc. ACM Int. Conf. Computer Vision and Pattern Recognition 2011 (<b><span
     style='color:brown'>CVPR'11</span></b>).<br>
     (<a href="http://www.csie.ntu.edu.tw/~winston/papers/kuo11unsupervised.pdf">paper</a>)
     <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-H.
     Kuo, Y.-L. Wu, K.-T. Chen, <span style='mso-bidi-font-weight:bold'>Y.-H.
     Yang</span>, T.-H. Chiu, and W.-H. Hsu, <br>
     &quot;<b>A technical demonstration of large-scale image object retrieval
     by efficient query evaluation and effective auxiliary visual feature
     discovery</b>,&quot; <br>
     in Proc. ACM Int. Conf. Multimedia 2010 (<b><span style='color:brown'>MM'10</span></b>),
     technical demonstration.<br>
     (<a href="http://dl.acm.org/citation.cfm?doid=1873951.1874286">paper</a>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     Y.-C. Lin, A. Lee, and H.-H. Chen, <br>
     &quot;<b>Improving musical concept detection by ordinal regression and
     context fusion</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval 2009 (<b><span
     style='color:brown'>ISMIR'09</span></b>), pp. 147-152. <br>
     (<a href="https://archives.ismir.net/ismir2009/paper/000045.pdf">paper</a>,
     <a href="pub/ISMIR09_tag_poster.pdf">poster</a>) <o:p></o:p></span></li>
</ul>

<h3><a name=separation><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:separation'><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Source
Separation</span></span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><span
style='mso-spacerun:yes'>&nbsp; </span></span><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to <a href="#top">top</a>)</span><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<p class=MsoListParagraph style='margin-top:0cm;margin-right:0cm;margin-bottom:
12.0pt;margin-left:36.0pt;mso-para-margin-top:0cm;mso-para-margin-right:0cm;
mso-para-margin-bottom:12.0pt;mso-para-margin-left:0gd;text-indent:-18.0pt;
mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:12.0pt;font-family:Symbol;
mso-fareast-font-family:Symbol;mso-bidi-font-family:Symbol'><span
style='mso-list:Ignore'>&middot;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US style='font-family:"Verdana",sans-serif'>Ching-Yu
Chiu, Wen-Yi Hsiao, Yin-Cheng Yeh, Yi-Hsuan Yang, and Alvin W. Y. Su, <br>
&quot;<b style='mso-bidi-font-weight:normal'>Mixing-specific data augmentation
techniques for improved blind violin/piano source separation</b>,&quot; <br>
in Proc. IEEE Int. Workshop on Multimedia Signal Processing 2020 (<b><span
style='color:brown'>MMSP&#8217;20</span></b>),<br>
(<a href="https://arxiv.org/abs/2008.02480">paper</a>, <a
href="https://github.com/SunnyCYC/aug4mss">code</a>, <a
href="https://sunnycyc.github.io/aug4mss_demo">demo</a>)<o:p></o:p></span></p>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jen-Yu Liu and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Dilated convolution with
     dilated GRU for music source separation</b>,&quot; <br>
     in Proc. Int. Joint Conf. Artificial Intelligence 2019 (<b><span
     style='color:brown'>IJCAI&#8217;19</span></b>;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>acceptance
     rate: 17.9%),<br>
     (<a href="https://arxiv.org/abs/1906.01203">paper</a>).<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Jen-Yu Liu and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Denoising auto-encoder with
     recurrent skip connections and residual regression for music source
     separation</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Machine Learning and Applications (<b><span
     style='color:brown'>ICMLA&#8217;18</span></b>).<br>
     (<a href="https://arxiv.org/abs/1807.01898">paper</a>, <a
     href="http://mss.ciaua.com/">demo</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>T.-S. Chan</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> and Y.-H. Yang, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Informed group-sparse representation for singing voice separation</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Letters
     (<b><span style='color:brown'>SPL</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 24, no. 2, pp. 156-160, Feb. 2017</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://ieeexplore.ieee.org/document/7805227/">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/chan17spl.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>T.-S. Chan</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> and Y.-H. Yang, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Polar <i style='mso-bidi-font-style:normal'>n</i>-complex and <i
     style='mso-bidi-font-style:normal'>n</i>-bicomplex singular value
     decomposition and principal component pursuit</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Transactions on Signal Processing</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>TSP</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 64, no. 24, pp. 6533-6544, Dec. 2016 </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://arxiv.org/abs/1801.03773">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/ikala/code.html">code</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/chan16tsp.txt">bib</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>P.-K. Jao, L. Su, Y.-H. Yang and
     B. Wohlberg, <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Monaural music source separation using convolutional
     sparse coding</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     <br>
     IEEE/ACM Transactions on Audio, Speech, and Language Processing (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>TASLP</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>), <br>
     vol. 24, no. 11, pp. 2158-2170, Nov. 2016</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/7533514">paper</a>, <a
     href="https://bitbucket.org/nafraw/opensource-taslp16-csc_source_separation/">code</a>)
     [<a href="http://mac.citi.sinica.edu.tw/research/CSC_separation/">project
     page</a>]<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>T.-S. Chan</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> and Y.-H. Yang, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Complex and quaternionic principal component pursuit and its
     application to audio separation</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Letters
     (<b><span style='color:brown'>SPL</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 23, no. 2, pp. 287-291, Feb. 2016<br>
     (<a href="https://arxiv.org/pdf/1801.03816">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/ikala/code.html">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>P.-K. Jao, Y.-H. Yang, and B.
     Wohlberg,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Informed monaural source
     separation of music based on convolutional sparse coding</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;15</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a
     href="http://math.lanl.gov/~brendt/Publications/Docs/jao-2015-informed.pdf">paper</a>,
     <a
     href="https://bitbucket.org/nafraw/opensource-taslp16-csc_source_separation/">code</a>,
     <a href="http://mac.citi.sinica.edu.tw/research/CSC_separation/">project</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>T.-S. Chan, T.-C. Yeh, Z.-C. Fan,
     H.-W. Chen, L. Su, Y.-H. Yang, and J.-S. Jang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Vocal activity informed
     singing voice separation with the IKALA dataset</b>,&quot;<br>
     IEEE International Conference on Acoustics, Speech and Signal Processing
     2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>ICASSP</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;15</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://ieeexplore.ieee.org/document/7178063">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/ikala/">data</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Low-rank representation of both singing voice and music
     accompaniment via learned dictionaries</b></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;<br>
     in Proc. Int. Society for Music Information Retrieval 201</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>3</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (<b><span style='color:brown'>ISMIR'1</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     pp. 427-432.</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'><br>
     (<a href="https://archives.ismir.net/ismir2013/paper/000017.pdf">paper</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     <br>
     &quot;<b>On sparse and low-rank matrix decomposition for singing voice
     separation</b>,&quot; <br>
     in Proc. ACM Multimedia 2012 (<b><span style='color:brown'>MM'12</span></b>),
     short paper, pp. </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>757</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>760</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2393347.2396305">paper</a>) <o:p></o:p></span></li>
</ul>

<h3><a name=transcription><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:transcription'><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Music
Transcription </span></span><span lang=EN-US style='font-size:14.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><span
style='mso-spacerun:yes'>&nbsp;</span></span><span lang=EN-US style='font-size:
11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'>(back to <a
href="#top">top</a>)</span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Hua
     Chen, Yuan-Chiao Cheng, Yen-Tung Yeh, Jui-Te Wu, Jyh-Shing Roger Jang, and
     Yi-Hsuan Yang,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;<b
     style='mso-bidi-font-weight:normal'>Towards generalizability to tone and
     content variations in the transcription of amplifier rendered electric
     guitar audio</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/2504.07406</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>April
     2025.<br>
     (<a href="https://arxiv.org/abs/2504.07406">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Ching-Yu
     Chiu, Meinard </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>M&uuml;ller</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, Matthew E. P. Davies, Alvin Wen-Yu Su, and Yi-Hsuan
     Yang,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;<b
     style='mso-bidi-font-weight:normal'>Local periodicity-based beat tracking
     for expressive classical piano music</b>,&quot;<br>
     IEEE/ACM Transactions on Audio, Speech, and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), vol. 31, pp. 2824-2835, July 2023.<br>
     (<a href="https://ieeexplore.ieee.org/document/10190128">paper</a>, <a
     href="https://github.com/SunnyCYC/plpdp4beat">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Ching-Yu
     Chiu, Meinard </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>M&uuml;ller</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, Matthew E. P. Davies, Alvin Wen-Yu Su, and Yi-Hsuan Yang,<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>&quot;<b
     style='mso-bidi-font-weight:normal'>An analysis method for metric-level
     switching in beat tracking</b>,&quot;<br>
     IEEE Signal Processing Letters (<b><span style='color:brown'>SPL</span></b>),
     vol. 29, pp. 2153-2157, Oct. 2022.<br>
     (<a href="https://arxiv.org/abs/2210.06817">paper</a>, <a
     href="https://github.com/SunnyCYC/acr4mls">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yu-Hua Chen, Wen-Yi Hsiao,
     Tsu-Kuang Hsieh, Jyh-Shing Roger Jang, and Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Towards automatic
     transcription of polyphonic electric guitar music: A new dataset and a
     multi-loss transformer model</b>,&quot; <br>
     in Proc. IEEE International Conference on Acoustics, Speech and Signal
     Processing 2022 (<b><span style='color:brown'>ICASSP&#8217;22</span></b>).<br>
     (<a href="https://arxiv.org/pdf/2202.09907.pdf">paper</a>, <a
     href="https://ss12f32v.github.io/Guitar-Transcription/">demo</a>, <a
     href="https://ss12f32v.github.io/Guitar-Transcription/">data</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Ching-Yu
     Chiu, Alvin Wen-Yu Su, and Yi-Hsuan Yang, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Drum-aware
     ensemble architecture for improved joint musical beat and downbeat
     tracking</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>,</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>&quot;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Letters
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>SPL</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>vol. 28, pp. 1100-1104, May 2021</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://arxiv.org/abs/2106.08685">paper</a>, <a
     href="https://github.com/SunnyCYC/drum-aware4beat">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Ching-Yu Chiu, Joann Ching,
     Wen-Yi Hsiao, Yu-Hua Chen, Alvin Wen-Yu Su, Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Source separation-based data
     augmentation for improved joint beat and downbeat tracking</b>,&quot; <br>
     in Proc. European Signal Processing Conference 2021 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>EUSIPCO&#8217;21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/2106.08703">paper</a>, <a
     href="https://github.com/SunnyCYC/aug4beat">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Tsung-Han Hsieh, Li Su, and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>A streamlined encoder/decoder
     architecture for melody extraction</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2019 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ICASSP&#8217;19</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/1810.12947">paper</a>, <a
     href="https://github.com/bill317996/Melody-extraction-with-melodic-segnet">code</a>)</span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yun-Ning Hung, Yi-An Chen and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Multitask learning for
     frame-level instrument recognition</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2019 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ICASSP&#8217;19</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://arxiv.org/abs/1811.01143">paper</a>, <a
     href="https://github.com/biboamy/instrument-streaming">code</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yun-Ning Hung, Yi-An Chen and
     Yi-Hsuan Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Learning disentangled
     representations for timber and pitch in music audio</b>,&quot; <br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1811.03271</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>November
     2018.<br>
     (<a href="https://arxiv.org/pdf/1811.03271.pdf">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yun-Ning
     Hung and Yi-Hsuan Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Frame-level instrument recognition by timbre and pitch</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2018 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ISMIR'18</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>), pp. 135-142<br>
     (<a href="https://arxiv.org/abs/1806.09587"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>paper</span></a>, <a
     href="https://arxiv.org/pdf/1806.09587.pdf"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>arxiv</span></a>, <a
     href="https://biboamy.github.io/instrument-recognition/"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>demo</span></a>,
     <a href="https://biboamy.github.io/instrument-recognition/"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>code</span></a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/hung18ismir.txt"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>bib</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Lufei Gao, Li Su, Yi-Hsuan Yang,
     and Tan Lee<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Polyphonic piano note
     transcription with non-negative matrix factorization of differential
     spectrogram</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2017 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://ieeexplore.ieee.org/document/7952164">paper</a>)</span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>M.-H.
     Yang, L. Su and Y.-H. Yang, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Highlighting root notes in chord recognition using cepstral
     features and multi-task learning</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Asia Pacific Signal
     and Information Processing Association Annual Summit and Conf. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>2016 </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>(<b><span style='color:#C00000'>APSIPA ASC&#8217;16</span></b>).</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/yang16apsipa.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='mso-fareast-font-family:"Times New Roman";
     color:windowtext;text-decoration:none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>L. Su, T.-Y. Chuang and Y.-H.
     Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Exploiting frequency,
     periodicity and harmonicity using advanced time-frequency concentration
     techniques for multipitch estimation of choir and symphony</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval Conf. 2016 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ISMIR&#8217;16</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/su16ismir.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a
     href="https://sites.google.com/site/lisupage/research/new-methodology-of-building-polyphonic-datasets-for-amt"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-Y. Liang, L. Su, H.-M. Lin and<b
     style='mso-bidi-font-weight:normal'> </b>Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Musical offset detection of
     pitched instruments: the case of violin</b>,&quot; <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>5</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 281-287.<br>
     (<a href="http://ismir2015.uma.es/articles/118_Paper.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="http://mac.citi.sinica.edu.tw/offset_detection/"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>L. Su and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Escaping from the Abyss of
     Manual Annotation: New Methodology of Building Polyphonic Datasets for
     Automatic Music Transcription</b>,&quot;<br>
     in Proc. Int. Symp. Computer Music Multidisciplinary Research 2015 (<b><span
     style='color:#C00000'>CMMR</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:#C00000'>&#8217;1</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:#C00000'>5</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/su15cmmr.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.-</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>. </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Liang,
     L. Su</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> and Y.-H. Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Musical onset detection using constrained linear reconstruction</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Letters
     (<b><span style='color:brown'>SPL</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 22, no. 11, pp. 2142-2146, Nov. 2015<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/liang15spl.pdf">paper</a>,
     <a href="https://github.com/cheyuanl/OnsetDetectorCLR">code</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/liang15spl.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>L.
     Su and Y.-H. Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Combining spectral and temporal representations for multipitch
     estimation of polyphonic music</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>/ACM</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Transactions on Audio, Speech, and Language Processing (<b><span
     style='color:brown'>TASLP</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 23, no. 10, pp. 1600-612, Oct. 2015<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/su15taslp.pdf">paper</a>,
     <a href="http://mac.citi.sinica.edu.tw/~yang/bib/su15taslp.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>L. Su and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Power-scaled spectral flux
     and peak-valley group-delay methods for robust musical onset detection</b>,&quot;<br>
     in Proc. Sound and Music Computing Conf. 2014 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:#C00000'>SMC&#8217;14</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>).<br>
     (<a href="../~yang/pub/su14smc_onset.pdf"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>L. Su, L.-F. Yu, Y.-H. Yang, and
     H.-Y. Lai,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Resolving octave ambiguities:
     A cross-dataset Investigation</b>,&quot;<br>
     in Proc. Sound and Music Computing Conf. 2014 (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:#C00000'>SMC&#8217;14</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>).<br>
     (<a href="../~yang/pub/su14smc_octave.pdf"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>paper</span></a>, <a
     href="http://mac.citi.sinica.edu.tw/db_Octave"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C.-T.
     Lee, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span> and H.-H.
     Chen, <br>
     &quot;<b>Multipitch </b></span><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>e</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>stimation
     of </span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif'>p</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>iano </span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>m</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>usic by </span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>e</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>xemplar-</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>b</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>ased
     </span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif'>s</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>parse </span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>r</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>epresentation</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,&quot; <br>
     IEEE Transactions on Multimedia (<b><span style='color:brown'>TMM</span></b>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>vol. 14, no. 3, pp. 608-618,
     Jun. 2012.<br>
     (<a href="https://ieeexplore.ieee.org/document/6172242">paper</a>) </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>[<a
     href="http://mpac.ee.ntu.edu.tw/personal/ader888/public_html/transcription/index.html">project
     page</a>]</span><span lang=EN-US style='mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>C.-D.
     Lee, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, and H.-H.
     Chen, <br>
     &quot;<b>Automatic transcription of piano music by sparse representation
     of magnitude spectra</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2011 (<b><span
     style='color:#C00000'>ICME'11</span></b>).<br>
     (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012000"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)
     [<a href="http://mpac.ee.ntu.edu.tw/~ader888/transcription/"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>project
     page</span></a>] <o:p></o:p></span></li>
</ul>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
     mso-list:l4 level1 lfo6;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>H.-T.
     Cheng, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, Y.-C.
     Lin, I.-B. Liao, and H.-H. Chen, <br>
     &quot;<b>Automatic chord recognition for music classification and
     retrieval</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2008 (<b><span
     style='color:#C00000'>ICME'08</span></b>), Hannover, Germany, pp.
     1505-1508.<br>
     (<a
     href="http://ieeexplore.ieee.org/document/4607732/?reload=true&amp;arnumber=4607732"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)
     </span><span class=MsoHyperlink><span lang=EN-US style='color:windowtext;
     text-decoration:none;text-underline:none'><o:p></o:p></span></span></li>
</ul>

<h3><a name=structure><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:structure'><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Structure
Analysis</span></span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'> </span><span
lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to </span><span lang=EN-US style='mso-fareast-font-family:"Times New Roman"'><a
href="#top"><span style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:
"Verdana",sans-serif;font-weight:normal;mso-bidi-font-weight:bold'>top</span></a></span><span
lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>)</span><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Taejun
     Kim, Yi-Hsuan Yang, and Juhan Nam, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Joint estimation of fader and equalizer gains of DJ mixers using
     convex optimization</b>,&quot;&nbsp;</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     in </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Proc. Int. Conf. Digital Audio
     Effects</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     2022</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> (<b><span style='color:brown'>DAFx</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>&#8217;22</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.<br>
     (<a
     href="https://dafx2020.mdw.ac.at/proceedings/papers/DAFx20in22_paper_33.pdf">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Taejun
     Kim, Yi-Hsuan Yang, and Juhan Nam, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Reverse-engineering the transition regions of real-world DJ mixes
     using sub-band analysis with convex optimization</b>,&quot;&nbsp;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Proc. International Conference
     on New Interface for Musical Expression</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> 2021</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     (<b><span style='color:brown'>NIME</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>&#8217;21</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.<br>
     (<a href="https://nime.pubpub.org/pub/g7avj1a7/release/1">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Taejun
     Kim</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>Minsuk Choi</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Evan Sacks</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>Yi-Hsuan Yang</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>, and </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Juhan Nam</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>A
     computational analysis of real-world DJ mixes using mix-to-track
     subsequence alignment</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif'>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Int.
     Society for Music Information Retrieval</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> Conf. 2020 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>ISMIR'</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:brown'>20</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (</span><span lang=EN-US><a href="https://arxiv.org/abs/2008.10267"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://github.com/mir-aidj/djmix-analysis"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Siang
     Huang, S</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>zu</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>u</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Chou and Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>i</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>suan</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Pop music highlighter: Marking the emotion keypoints</b>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     Transactions of the International Society for Music Information Retrieval </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>(<b><span style='color:brown'>T</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>ISMIR</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>),</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol.1, no. 1, pp. 68-78, 2018.<br>
     (</span><span lang=EN-US><a
     href="https://transactions.ismir.net/articles/10.5334/tismir.14/"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://github.com/remyhuang/pop-music-highlighter"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://arxiv.org/abs/1802.10495"><span
     style='font-family:"Verdana",sans-serif'>arxiv</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Siang
     Huang, S</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>zu</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>u</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Chou and Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>i</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>suan</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Yang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Generating music medleys via playing music puzzle games</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Proc. AAAI Conf. Artificial Intelligence (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:brown'>AAAI&#8217;18</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>)</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>2018<br>
     (</span><span lang=EN-US><a href="https://arxiv.org/abs/1709.04384"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://remyhuang.github.io/DJnet/"><span
     style='font-family:"Verdana",sans-serif'>demo</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://github.com/remyhuang/music-puzzle-games"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/huang18aaai.txt"><span
     style='font-family:"Verdana",sans-serif'>bib</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Siang
     Huang, S</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>zu</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>u</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Chou and Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>i</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>suan</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Yang,<span style='mso-spacerun:yes'>&nbsp; </span></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>DJnet: A Dream for Making An Automatic DJ</b>,&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     ISMIR </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>demo paper</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (non-peer reviewed two-page
     extended abstract) 2017 (</span><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";color:brown'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>7-LBD</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (</span><span lang=EN-US><a
     href="https://remyhuang.github.io/files/huang17ismir-lbd.pdf"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Siang
     Huang, S</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>zu</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>u</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Chou and Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>i</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-H</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>suan</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Yang,<span style='mso-spacerun:yes'>&nbsp; </span></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Music thumbnailing via neural attention modeling of music emotion</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Asia Pacific Signal
     and Information Processing Association Annual Summit and Conf.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> 2017</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (<b><span style='color:brown'>APSIPA ASC&#8217;17</span></b>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, pp. 347-350</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (</span><span lang=EN-US><a
     href="https://ieeexplore.ieee.org/document/8282049"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://remyhuang.github.io/DJnet/"><span
     style='font-family:"Verdana",sans-serif'>demo</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>M.-Y.
     Su, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, Y.-C. Lin,
     and H.-H. Chen, <br>
     &quot;<b>An integrated approach to music boundary detection</b>,&quot; <br>
     in Proc. Int. Society for Music Information Retrieval 2009 (<b><span
     style='color:brown'>ISMIR'09</span></b>), pp. 705-710. <br>
     (</span><span lang=EN-US><a
     href="https://archives.ismir.net/ismir2009/paper/000115.pdf"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US><a
     href="pub/ISMIR09_segm_poster.pdf"><span style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>poster</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l5 level1 lfo2;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>H.-T.
     Cheng, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, Y.-C.
     Lin, and H.-H. Chen, <br>
     &quot;<b>Multimodal structure segmentation and analysis of music using
     audio and textual information</b>,&quot; <br>
     in Proc. IEEE Int. Symp. Circuits and Systems 2009 (<b><span
     style='color:brown'>ISCAS'09</span></b>), Taipei, Taiwan, pp. 1677-1680. <br>
     (</span><span lang=EN-US><a
     href="https://users.ece.cmu.edu/~hengtzec/papers/iscas09_musicstructure.pdf"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) [</span><span lang=EN-US><a
     href="http://sites.google.com/site/hengtzecheng/projects/iscas09"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>project
     page</span></a></span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, include dataset] <o:p></o:p></span></li>
</ul>

<h3><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></h3>

<h3><a name=performance><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Performance/expressivity</span></a><span
lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'> </span><span lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
font-weight:normal;mso-bidi-font-weight:bold'>(back to <a href="#top">top</a>)</span><span
class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
none;text-underline:none'><o:p></o:p></span></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Ting-Wei
     Su, Yuan-Ping Chen, Li Su, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>and </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Yi-Hsuan Yang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>TENT: Technique-embedded note tracking for real-world guitar solo
     recordings</b>,&quot; </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     Transactions of the International Society for Music Information Retrieval </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>(<b><span style='color:brown'>T</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>ISMIR</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>),</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 2, no. 1, pp. 15-28, 2019</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://transactions.ismir.net/articles/10.5334/tismir.23/">paper</a>)</span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chi-Ching Shih, Pei-Ching Li,
     Yi-Ju Lin, Alvin W. Y. Su, Li Su and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Analysis and synthesis of the
     violin playing styles of Heifetz and Oistrakh</b>,&quot; <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Conf. Digital Audio
     Effects</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     2017 (<b><span style='color:#C00000'>DAFx</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>'1</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>7</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>),<br>
     accepted for publication<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/shih17dafx.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-H. Yang, P.-C. Li, A. W. Y.
     Su, L. Su, and<b style='mso-bidi-font-weight:normal'> </b>Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Automatic violin synthesis
     using expressive musical term features</b>,&quot; <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Conf. Digital Audio
     Effects</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     2016 (<b><span style='color:#C00000'>DAFx</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>'1</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>6</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), <br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/yang16dafx.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yin-Jyun Luo, Li Su, Yi-Hsuan
     Yang and Tai-Shih Chi, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Detection of common mistakes
     in novice violin playing</b>,&quot; <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>5</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 316-322.<br>
     (<a href="http://ismir2015.uma.es/articles/197_Paper.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Yuan-Ping Chen, Li Su and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Electric guitar playing
     technique detection in real-world recording based on F0 sequence pattern
     recognition</b>,&quot; <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>5</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 708-714.<br>
     (<a href="http://ismir2015.uma.es/articles/119_Paper.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="http://mac.citi.sinica.edu.tw/GuitarTranscription"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Pei-Ching Li, Li rSu, Yi-Hsuan
     Yang and Alvin W. Y. Su, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Analysis of expressive musical
     terms in violin using score-informed and expression-based audio features</b>,&quot;
     <br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2015 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>5</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 809-815.<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/li15ismir.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="https://sites.google.com/site/pclipatty/scream-mac-emt-dataset"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Li Su, Li-Fan Yu arnd Yi-Hsuan
     Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Sparse cepstral and phase
     codes for guitar playing technique classification</b>,&quot;<br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>4</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 9-14.<br>
     (<a
     href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T003_213_Paper.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="http://mac.citi.sinica.edu.tw/GuitarTranscription"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>data</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
</ul>

<h3><a name=recommendation><span lang=EN-US style='font-size:14.0pt;mso-fareast-font-family:
"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:recommendation'><span lang=EN-US
style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'>Recommendation</span></span><span lang=EN-US
style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'> </span><span lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
font-weight:normal;mso-bidi-font-weight:bold'>(back to <a href="#top">top</a>)</span><span
lang=EN-US style='font-size:14.0pt;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Szu-Yu
     Chou, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Jyh-Shing
     Roger Jang,</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> and Yi-Hsuan Yang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Fast tensor factorization for large-scale context-aware
     recommendation from implicit feedback</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Trans</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>actions on</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Big Data (</span><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;color:brown'>TBD</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 6, no. 1, pp. 201-208, Mar. 2020.<br>
     (</span><span lang=EN-US><a
     href="https://ieeexplore.ieee.org/document/8585106"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, bib)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chih-Ming Chen, Chuan-Ju Wang,
     Ming-Feng Tsai and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Collaborative similarity
     embedding for recommender systems</b>,&quot; <br>
     in Proc. the Web Conference 2019 (<b><span style='color:brown'>WWW&#8217;19</span></b>),
     short paper (acceptance rate 20%),<br>
     (</span><span lang=EN-US><a href="https://arxiv.org/abs/1902.06188"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chia-An Yu, Ching-Lun Tai,
     Tak-Shing Chan and Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Modeling multi-way relations
     with hypergraph embedding</b>,&quot; <br>
     in Proc. ACM International Conference on Information and Knowledge
     Management 2018 (<b><span style='color:brown'>CIKM&#8217;18</span></b>), <br>
     accepted.<br>
     (paper, </span><span lang=EN-US><a href="https://github.com/chia-an/HGE"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, bib) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Asmita Poddar, Eva Zangerle, and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>#nowplaying-RS: A new
     benchmark dataset for building context-aware music recommender systems</b>,&quot;<br>
     <span style='mso-spacerun:yes'>&nbsp;</span>in Proc. Sound and Music
     Computing Conf. 2018 (<b><span style='color:brown'>SMC&#8217;18</span></b>),
     <br>
     accepted.<br>
     (</span><span lang=EN-US><a
     href="https://evazangerle.at/publication/poddar-smc-2018/poddar-smc-2018.pdf"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a
     href="https://github.com/asmitapoddar/nowplaying-RS-Music-Reco-FM"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="http://dbis-nowplaying.uibk.ac.at/#nowplayingrs"><span
     style='font-family:"Verdana",sans-serif'>data</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chih-Ming Chen, Yi-Hsuan Yang,
     Yi-An Chen, Ming-Feng Tsai,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Vertex-context sampling for
     weighted network embedding</b>,&quot;<br>
     in</span><span lang=EN-US> </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>ArXiv e-prints, abs/1711.00227</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>Nov
     2017.<br>
     (</span><span lang=EN-US><a href="https://arxiv.org/abs/1711.00227"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Chia-An Yu, Tak-Shing Chan and
     Yi-Hsuan Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Low-rank matrix completion
     over finite Abelian group algebras for context-aware recommendation</b>,&quot;
     <br>
     in Proc. ACM International Conference on Information and Knowledge
     Management 2017 (<b><span style='color:brown'>CIKM&#8217;17</span></b>), <br>
     accepted.<br>
     (</span><span lang=EN-US><a
     href="https://dl.acm.org/doi/10.1145/3132847.3133057"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="https://github.com/versesrev/MC-AGA"><span
     style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>S.-Y. Chou, L.-C. Yang, Y.-H.
     Yang, and J.-S. Jang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Conditional preference nets
     for user and item cold start problems in music recommendation</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2017 (<b><span
     style='color:brown'>ICME&#8217;17</span></b>).<br>
     (</span><span lang=EN-US><a
     href="https://ieeexplore.ieee.org/document/8019472"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>S.-Y. Chou, Y.-H. Yang, J.-S.
     Jang and Y.-C. Lin,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Addressing cold start for
     next-song recommendation</b>,&quot;<br>
     in Proc. ACM Recommender Systems (<b><span style='color:brown'>RecSys&#8217;16</span></b>),
     4-page short paper for oral presentation, pp. 115-118, <br>
     (</span><span lang=EN-US><a
     href="http://dl.acm.org/citation.cfm?id=2959156"><span style='font-family:
     "Verdana",sans-serif'>paper</span></a></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>, </span><span lang=EN-US><a
     href="https://github.com/fearofchou/ALMM"><span style='font-family:"Verdana",sans-serif'>code</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-M. Chen, M.-F. Tsai, Y.-C. Lin
     and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Query-based music
     recommendations via preference embedding</b>,&quot;<br>
     in Proc. ACM Recommender Systems (<b><span style='color:brown'>RecSys&#8217;16</span></b>),
     4-page short paper for oral presentation, pp. 79-82. <br>
     (</span><span lang=EN-US><a
     href="http://dl.acm.org/citation.cfm?id=2959169"><span style='font-family:
     "Verdana",sans-serif'>paper</span></a></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>, </span><span lang=EN-US><a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/chen16recsys.txt"><span
     style='font-family:"Verdana",sans-serif'>bib</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-M. Chen, P.-C. Chien, M.-F.
     Tsai, Y.-H. Yang and Y.-C. Lin,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Exploiting latent social
     listening representations for music recommendations</b>,&quot;<br>
     in Proc. ACM Recommender Systems (<b><span style='color:brown'>RecSys&#8217;15</span></b>),
     2-page poster paper. <br>
     (</span><span lang=EN-US><a
     href="http://ceur-ws.org/Vol-1441/recsys2015_poster6.pdf"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>S.-Y. Chou, Y.-H. Yang, and Y.-C.
     Lin,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Evaluating music
     recommendation in a real-world setting: On data splitting and evaluation
     metrics</b>,&quot;<br>
     in Proc. IEEE Int. Conf. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Multimedia and Expo.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> (<b><span
     style='color:brown'>ICME&#8217;15</span></b>). (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:green'>Best Paper Award</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<br>
     (</span><span lang=EN-US><a
     href="https://ieeexplore.ieee.org/document/7177456"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-M. Chen, H.-P. Chen, M.-F.
     Tsai, and Y.-H. Yang, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Leverage item popularity and
     recommendation quality via cost-sensitive factorization machines</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Data Mining (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:brown'>ICDM&#8217;14</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>), Ph.D. forum paper.<br>
     (</span><span lang=EN-US><a
     href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7022726"><span
     style='font-family:"Verdana",sans-serif'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-M. Chen, M.-F. Tsai, J.-Y.
     Liu, and Y.-H. Yang,<br>
     &quot;</span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Using
     </span></b><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>e</span></b><b style='mso-bidi-font-weight:
     normal'><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>motional </span></b><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>c</span></b><b style='mso-bidi-font-weight:normal'><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>ontext from </span></b><b style='mso-bidi-font-weight:
     normal'><span lang=EN-US style='font-family:"Verdana",sans-serif'>a</span></b><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>rticle for
     </span></b><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>c</span></b><b style='mso-bidi-font-weight:
     normal'><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>ontextual </span></b><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>m</span></b><b style='mso-bidi-font-weight:normal'><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>usic </span></b><b style='mso-bidi-font-weight:normal'><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>r</span></b><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>ecommendation</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>&quot;</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     <br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>ACM</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Int. Conf. Multimedia 201</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>3</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>MM</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     short paper (acceptance rate 30%).</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (</span><span lang=EN-US><a
     href="http://www.cs.nccu.edu.tw/~mftsai/papers/mm2013-short_tsai.pdf"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a
     href="http://www.cs.nccu.edu.tw/~mftsai/papers/mm2013-short_tsai.mp4"><span
     style='font-family:"Verdana",sans-serif'>demo</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-M. Chen, M.-F. Tsai, J.-Y.
     Liu, and Y.-H. Yang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Music recommendation based on
     multiple contextual similarity information</b>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>&quot;</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. IEEE/WIC/ACM</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> Int. Conf. Web
     Intelligence</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> 201</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>3</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>WI</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><br>
     (</span><span lang=EN-US><a
     href="http://www.cs.nccu.edu.tw/~mftsai/papers/wi2013_tsai.pdf"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-C</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Teng, Y</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>-S</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     Kuo, and Y</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-H</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>A large in-situ dataset for context-aware music recommendation on
     smartphones</b>,&quot; </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Int. Conf. Multimedia and
     Expo. 2013 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:brown'>ICME</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:brown'>'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:brown'>3</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>,
     short paper</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>(</span><span lang=EN-US><a
     href="https://ieeexplore.ieee.org/document/6618254"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-Y.
     Liu and <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, <br>
     &quot;<b>Inferring personal traits from music listening history</b>,&quot;
     <br>
     in Int. Workshop on Music Information Retrieval with User-Centered and
     Multimodal Strategies (<b><span style='color:brown'>MIRUM'12</span></b>),
     in conjunction with ACM Multimedia (MM), pp. </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>31</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>-</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>36</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (</span><span lang=EN-US><a
     href="http://dl.acm.org/citation.cfm?id=2390848.2390856"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, </span><span
     lang=EN-US><a href="http://mac.citi.sinica.edu.tw/~yang/bib/liu12mirum.txt"><span
     style='font-family:"Verdana",sans-serif'>bib</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and H.-H. Chen, <br>
     &quot;<b>iMR: Interactive music recommendation via active interactive
     genetic algorithm</b>,&quot; <br>
     in Proc. Int. Workshop on Computer Music and Audio Technology 2009 (<b><span
     style='color:brown'>WOCMAT'09</span></b>), Taipei, Taiwan.<br>
     (</span><span lang=EN-US><a
     href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.381.4895&amp;rep=rep1&amp;type=pdf"><span
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>) <o:p></o:p></span></li>
</ul>

<h3><a name=video><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:video'><span lang=EN-US style='font-size:14.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Music
and Video</span></span><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'> </span><span
lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to <a href="#top">top</a>)</span><span class=MsoHyperlink><span
lang=EN-US style='color:windowtext;text-decoration:none;text-underline:none'><o:p></o:p></span></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Yu-Chih
     Tsai, Tse-Yu Pan, Ting-Yang Kao, Yi-Hsuan Yang, and Min-Chun Hu, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>EMVGAN: Emotion-aware
     music-video common representation learning via generative adversarial
     networks</b>,&quot; <br>
     in Proc. Int. Joint Workshop on Multimedia Artworks Analysis and
     Attractiveness Computing in Multimedia, in conjunction with ACM ICMR,
     2022.<br>
     (<a href="https://dl.acm.org/doi/10.1145/3512730.3533718">paper</a>, <a
     href="https://sites.google.com/mislab.csie.ncku.edu.tw/emvgan/">demo</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Jen-Yu
     Liu, Yi-Hsuan Yang, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>and
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Shyh-Kang Jeng, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Weakly-supervised visual instrument-playing action
     detection in videos</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Multimedia
     (<b><span style='color:brown'>TMM</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 21, no. 4, pp. 887-901, Apr. 2019.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><a
     href="https://arxiv.org/abs/1805.02031">paper</a></span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>)</span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Jen-Chun
     Lin, Wen-Li Wei, Tyng-Luh Liu, Yi-Hsuan Yang, Hsin-Min Wang, Hsiao-Rong
     Tyan, and Hong-Yuan Mark Liao, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>C</span></b><b style='mso-bidi-font-weight:normal'><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>oherent deep-net fusion to classify shots in concert
     videos</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>,&quot; </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Multimedia
     (<b><span style='color:brown'>TMM</span></b>), </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     vol. 20, no. 11, pp. 3123-3136, Nov. 2018.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
     (</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><a
     href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=8327906&amp;source=authoralert">paper</a>,
     <a href="https://sites.google.com/site/sinica519/demo">demo</a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Wen-Li Wei, Jen-Chun Lin,
     Tyng-Luh Liu, Yi-Hsuan Yang, Hsin-Min Wang, Hsiao-Rong Tyan, and Hong-Yuan
     Mark Liao,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>SeetheVoice: Learning from
     music to visual storytelling of shots</b>,&quot; <br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2018 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ICME</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>&#8217;18</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="https://homepage.iis.sinica.edu.tw/papers/whm/23229-F.pdf">paper</a>,
     <a href="https://sites.google.com/site/music2shots/"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>demo</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Wen-Li Wei, Jen-Chun Lin,
     Tyng-Luh Liu, Yi-Hsuan Yang, Hsin-Min Wang, Hsiao-Rong Tyan, and Hong-Yuan
     Mark Liao,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Deep-net fusion to classify
     shots in concert videos</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing 2017 (</span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman";color:#C00000'>ICASSP</span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>&#8217;17</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>).<br>
     (<a href="http://www.iis.sinica.edu.tw/papers/liutyng/20663-F.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="https://sites.google.com/site/ewdeepccm2/demo"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>demo</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>C.-H. Yeh,<b style='mso-bidi-font-weight:
     normal'> </b>Y.-H. Yang, M.-H. Chang, and H.-Y. M. Liao, <br>
     &quot;<b style='mso-bidi-font-weight:normal'>Music driven human motion
     manipulation for characters in a video</b>,&quot;<br>
     in Proc. IEEE Int. Symp. Multimedia (</span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     color:#C00000'>ISM</span></b><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:#C00000'>&#8217;14</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>).<br>
     (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033027"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)<span
     class=MsoHyperlink><span style='color:windowtext;text-decoration:none;
     text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Ju-Chiang Wang, Ming-Chi Yan,
     Yi-Hsuan Yang and Hsin-Min Wang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Automatic set list
     identification and song segmentation of full-length concert videos</b>,&quot;<br>
     in Proc. </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Int. Society for Music
     Information Retrieval</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     Conf. 2014 (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:#C00000'>ISMIR'1</span></b><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>4</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>), pp. 239-244.<br>
     (<a
     href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T044_211_Paper.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)
     <span class=MsoHyperlink><span style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>J.-C.
     Wang, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, I.-H.
     Jhuo, Y.-Y. Lin, and H.-M. Wang,<br>
     &quot;<b>The Acousticvisual</b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> </span></b><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Emotion
     Gaussians model for automatic generation of music video</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,&quot; <br>
     in Proc. ACM Multimedia 2012 (<b><span style='color:#C00000'>MM'12</span></b>),
     <b><span style='color:#00B050'>Grand Challenge solution paper (first
     prize)</span></b>, pp. </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>1379</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>-1</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>380</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<br>
     (<a href="http://dl.acm.org/citation.cfm?id=2393347.2396494"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a></span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>, <a
     href="http://slam.iis.sinica.edu.tw/demo/MVGen/"><span style='color:windowtext;
     text-decoration:none;text-underline:none'>demo</span></a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l2 level1 lfo3;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>K.-S.
     Lin, A. Lee, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>,
     C.-D. Lee, and H.-H. Chen, <br>
     &quot;<b>Automatic highlights extraction for drama video using music
     emotion and human face features</b>,&quot; <br>
     in Proc. IEEE Int. Workshop on Multimedia Signal Processing 2011 (<b><span
     style='color:#C00000'>MMSP'11</span></b>).<br>
     (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6093831"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>.</span><span
     class=MsoHyperlink><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman";color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
</ul>

<h3><a name=retrieval><span lang=EN-US style='font-size:14.0pt'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:retrieval'><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Retrieval</span></span><span
lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'> </span><span lang=EN-US style='font-size:11.0pt;mso-bidi-font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
font-weight:normal;mso-bidi-font-weight:bold'>(back to <a href="#top">top</a>)</span><span
class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
none;text-underline:none'><o:p></o:p></span></span></h3>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>P.-I.
     Chen, J.-Y. Liu, and Y.-H. Yang, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Personal Factors in Music Preference and Similarity: User Study on
     the Role of Personality Traits</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Int. Symp. Computer Music
     Multidisciplinary Research</span><span lang=EN-US style='font-family:"Verdana",sans-serif'>
     2015</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> (<b><span style='color:#C00000'>CMMR</span></b></span><b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;color:#C00000'>&#8217;15</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>), </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/chen15cmmr.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<span class=MsoHyperlink><span style='color:windowtext;
     text-decoration:none;text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     W.-H. Hsu, and H.-H. Chen, <br>
     &quot;<b>Online reranking via ordinal informative concepts for context fusion
     in concept detection and video search</b>,&quot; <br>
     IEEE Transactions on Circuits and Systems for Video Technology (<b><span
     style='color:brown'>TCSVT</span></b>), <br>
     vol. 19, no. 12, pp. 1880-1890, Dec. 2009.<br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/yang10tcsvt.pdf">paper</a>)
     </span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,
     P.-T. Wu, C.-W. Lee, K.-H. Lin, W.-H. Hsu, and H.-H. Chen, <br>
     &quot;<b>ContextSeer: Context search and recommendation at query time for
     shared consumer photos</b>,&quot; <br>
     in Proc. ACM Multimedia 2008 (<b><span style='color:#C00000'>MM'08</span></b>)
     (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif'>full
     paper</span></b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, content track, <b>accept
     rate=21%</b>), pp. 199-208. <br>
     (<a href="http://www.csie.ntu.edu.tw/~winston/doc/hsu08contextseer.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>,
     <a href="pub/MM08_rrk.ppt.pdf"><span style='color:windowtext;text-decoration:
     none;text-underline:none'>slides</span></a>) [<a href="reranking"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>project
     page</span></a>, include dataset] </span><span class=MsoHyperlink><span
     lang=EN-US style='color:windowtext;text-decoration:none;text-underline:
     none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>P.-T.
     Wu, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, K.-T. Chen,
     W.-H. Hsu, T.-H. Li, and C.-J. Lee, <br>
     &quot;<b>Keyword-based co</b></span><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>r</span></b><b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>ncept
     search on consumer photos by web-based kernel function</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>,&quot; <br>
     in Proc. ACM Multimedia 2008 (<b><span style='color:#C00000'>MM'08</span></b>)
     (poster, content track), pp. 651-654. <br>
     (<a
     href="http://www.cmlab.csie.ntu.edu.tw/~frankwbd/papers/ctsp3757-wu.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)
     <span class=MsoHyperlink><span style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
     mso-bidi-font-weight:bold'>Y.-H. Yang</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>
     and W.-H. Hsu, <br>
     &quot;<b>Video search reranking via online ordinal reranking</b>,&quot;<br>
     in Proc. IEEE Int. Conf. Multimedia and Expo. 2008 (<b><span
     style='color:#C00000'>ICME'08</span></b>), Hannover, Germany.<br>
     (<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4607427"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)
     </span></li>
</ul>

<h2><a name=editorial><span lang=EN-US style='font-size:14.0pt;font-family:
"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h2>

<h2><span style='mso-bookmark:editorial'><span lang=EN-US style='font-size:
14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Editorial
</span></span><span style='mso-bookmark:editorial'><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to </span></span><span style='mso-bookmark:editorial'></span><a
href="#top"><span style='mso-bookmark:editorial'><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>top</span></span><span style='mso-bookmark:editorial'></span></a><span
style='mso-bookmark:editorial'><span lang=EN-US style='font-size:11.0pt;
mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'>)</span></span><span
style='mso-bookmark:editorial'><span lang=EN-US style='font-size:14.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><o:p></o:p></span></span></h2>

<span style='mso-bookmark:editorial'></span>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l7 level1 lfo8;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Meinard M&uuml;ller, Emilia
     G&oacute;mez, and </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Yi-Hsuan Yang</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>Computational methods for melody and voice
     processing in music recordings</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     Report from Dagstuhl Seminar 19052</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     2019</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>.</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'> <br>
     (<a
     href="http://drops.dagstuhl.de/opus/volltexte/2019/10573/pdf/dagrep_v009_i001_p125_19052.pdf">paper</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l7 level1 lfo8;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>M. Schedl, Y.-H. Yang, and P.
     Herrera</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Introduction to intelligent music systems and applications</b>,&quot;
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>ACM Transactions on Intelligent
     Systems and Technology (<b><span style='color:brown'>TIST</span></b>),</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 8, no. 2, article 17, Dec. 2016</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://dl.acm.org/citation.cfm?id=2991468">paper</a>, <a
     href="http://mac.citi.sinica.edu.tw/~yang/bib/schedl16tist.txt">bib</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l7 level1 lfo8;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Hsin-Min
     Wang, Yi-Hsuan Yang, and Jin Ha Lee, </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><b style='mso-bidi-font-weight:normal'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>International
     Society for Music Information Retrieval Conference</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>, </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>Proceedings, ISMIR, Taipei,
     Taiwan, 2014.</span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a
     href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/ISMIR2014_Proceedings.pdf">link</a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'><o:p></o:p></span></li>
</ul>

<h3><a name=others><span lang=EN-US style='font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman"'><o:p>&nbsp;</o:p></span></a></h3>

<h3><span style='mso-bookmark:others'><span lang=EN-US style='font-size:14.0pt;
font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Others
</span></span><span style='mso-bookmark:others'><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>(back to </span></span><span style='mso-bookmark:others'></span><a
href="#top"><span style='mso-bookmark:others'><span lang=EN-US
style='font-size:11.0pt;mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;
mso-fareast-font-family:"Times New Roman";font-weight:normal;mso-bidi-font-weight:
bold'>top</span></span><span style='mso-bookmark:others'></span></a><span
style='mso-bookmark:others'><span lang=EN-US style='font-size:11.0pt;
mso-bidi-font-size:14.0pt;font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman";font-weight:normal;mso-bidi-font-weight:bold'>)</span><span
class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
none;text-underline:none'><o:p></o:p></span></span></span></h3>

<span style='mso-bookmark:others'></span>

<ul type=disc>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Ga&euml;l
     Richard, Vincent Lostanlen, Yi-Hsuan Yang, and Meinard M&uuml;ller, <br>
     </span><span lang=EN-US style='font-family:"&#26032;&#32048;&#26126;&#39636;",serif;
     mso-ascii-theme-font:minor-fareast;mso-fareast-font-family:PMingLiU;
     mso-fareast-theme-font:minor-fareast;mso-hansi-theme-font:minor-fareast'>&quot;</span><b
     style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Model-based
     deep learning for music information research</span></b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>,</span><span
     lang=EN-US style='font-family:"&#26032;&#32048;&#26126;&#39636;",serif;
     mso-ascii-theme-font:minor-fareast;mso-fareast-font-family:PMingLiU;
     mso-fareast-theme-font:minor-fareast;mso-hansi-theme-font:minor-fareast'>&quot;<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Signal Processing Magazine</span><span
     lang=EN-US style='font-family:"&#26032;&#32048;&#26126;&#39636;",serif;
     mso-ascii-theme-font:minor-fareast;mso-fareast-font-family:PMingLiU;
     mso-fareast-theme-font:minor-fareast;mso-hansi-theme-font:minor-fareast'> </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>(<b><span style='color:brown'>SPM</span></b>), <br>
     accepted for publication, 2024.<br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'>(<a
     href="https://hal.science/hal-04611461v2/document"><span style='color:
     windowtext;text-decoration:none;text-underline:none'>paper</span></a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Zhe-Cheng
     Fan, Tak-Shing T. Chan, Yi-Hsuan Yang, and Jyh-Shing R. Jang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Backpropagation with N-D vector-valued neurons using arbitrary
     bilinear products</b>,&quot; </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>IEEE Transactions on Neural
     Networks and Learning Systems (<b><span style='color:brown'>TNNLS</span></b>),
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     vol. 31, no. 7, pp. 2638-2652, 2020</span><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/8826334?source=authoralert">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Zhe-Cheng
     Fan, Tak-Shing Chan, Yi-Hsuan Yang and Jyh-Shing Jang, </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Deep cyclic group networks</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'>Int.</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> Joint Conf</span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>.</span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'> Neural Networks</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'> 2019</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'> (</span><b><span lang=EN-US style='font-family:"Verdana",sans-serif;
     color:#C00000'>IJCNN&#8217;19</span></b><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>), </span><span
     lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="https://ieeexplore.ieee.org/document/8851695"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif'>Z.-C. Fan, T.-S. T. Chan, Y.-H.
     Yang, and J.-S. R. Jang,<br>
     &quot;<b style='mso-bidi-font-weight:normal'>Music signal processing using
     vector product neural networks</b>,&quot;<br>
     International Workshop on Deep Learning for Music 2017 (<b><span
     style='color:brown'>DLM&#8217;17</span></b>).<br>
     (<a href="https://arxiv.org/abs/1706.09555">paper</a>)<o:p></o:p></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>P.-K.
     Jao, P.-I. Chen, and Y.-H. Yang, </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>&quot;<b style='mso-bidi-font-weight:
     normal'>Disk Jockey in Brain - A Prototype for Volume Control of Tracked
     Instrument during Playback</b>,&quot; </span><span lang=EN-US
     style='font-family:"Verdana",sans-serif'><br>
     </span><span lang=EN-US style='font-family:"Verdana",sans-serif;
     mso-fareast-font-family:"Times New Roman"'>in Proc. Int. Works.
     Brain-Computer Music Interfacing </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif'>2015 </span><span lang=EN-US style='font-family:
     "Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>(<b><span
     style='color:#C00000'>BCMI</span></b></span><b><span lang=EN-US
     style='font-family:"Verdana",sans-serif;color:#C00000'>&#8217;15</span></b><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>), </span><span lang=EN-US style='font-family:"Verdana",sans-serif'><br>
     (<a href="http://mac.citi.sinica.edu.tw/~yang/pub/jao15bcmi.pdf"><span
     style='color:windowtext;text-decoration:none;text-underline:none'>paper</span></a>)</span><span
     lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
     "Times New Roman"'>.</span><span class=MsoHyperlink><span lang=EN-US
     style='mso-fareast-font-family:"Times New Roman";color:windowtext;
     text-decoration:none;text-underline:none'><o:p></o:p></span></span></li>
 <li class=MsoNormal style='mso-margin-top-alt:auto;margin-bottom:12.0pt;
     mso-list:l1 level1 lfo7;tab-stops:list 36.0pt'><span lang=EN-US
     style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'>Y.-F.
     Su, <span style='mso-bidi-font-weight:bold'>Y.-H. Yang</span>, M.-T. Lu,
     and H.-H. Chen, <br>
     &quot;<b>Smooth control of adaptive media playout for video streaming</b>,&quot;
     <br>
     IEEE Transactions on Multimedia (<b><span style='color:brown'>TMM</span></b>),
     <br>
     vol. 11, no. 7, pp. 1331-1339, Nov. 2009.<br>
     (<a href="https://ieeexplore.ieee.org/document/5208269">paper</a>)</span><span
     class=MsoHyperlink><span lang=EN-US style='color:windowtext;text-decoration:
     none;text-underline:none'><o:p></o:p></span></span></li>
</ul>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<div style='margin-top:5.0pt;margin-bottom:5.0pt'>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span class=MsoHyperlink><span lang=EN-US
style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
color:windowtext;text-decoration:none;text-underline:none'><a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4607427"><span
style='color:windowtext;text-decoration:none;text-underline:none'><o:p></o:p></span></a></span></span></p>

<div class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span class=MsoHyperlink><span lang=EN-US
style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman";
color:windowtext;text-decoration:none;text-underline:none'><a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4607427"><span
style='color:windowtext;text-decoration:none;text-underline:none'>

<hr size=2 width="100%" align=center>

</span></a></span></span></div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<p class=MsoNormal align=center style='mso-margin-top-alt:auto;mso-margin-bottom-alt:
auto;text-align:center'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><b><span
lang=EN-US style='font-family:"Verdana",sans-serif;mso-fareast-font-family:
"Times New Roman"'>Copyright Notice:</span></b><span lang=EN-US
style='font-family:"Verdana",sans-serif;mso-fareast-font-family:"Times New Roman"'><br>
The documents on this page have been published by scholarly journals or
conferences for the purpose of non-commercial dissemination of scientific work.
These manuscripts are copyrighted by the authors and/or the
journals/conferences in which they are published. You may copy a manuscript for
scholarly, non-commercial purposes, provided that you agree with these terms. <br
style='mso-special-character:line-break'>
<![if !supportLineBreakNewLine]><br style='mso-special-character:line-break'>
<![endif]></span><span class=MsoHyperlink><span lang=EN-US style='color:windowtext;
text-decoration:none;text-underline:none'><o:p></o:p></span></span></p>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

</body>

</html>
